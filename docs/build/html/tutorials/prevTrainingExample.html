

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Model Training &mdash; tft-torch 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> tft-torch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">tft-torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">tft-torch Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help.html">Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">tft-torch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Model Training</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/tutorials/prevTrainingExample.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Model-Training">
<h1>Model Training<a class="headerlink" href="#Model-Training" title="Permalink to this headline">¶</a></h1>
<p>This tutorial demonstrates the training of the <code class="docutils literal notranslate"><span class="pre">TemporalFusionTransformer</span></code> model.</p>
<p>The demonstration is using the processed version of <a class="reference external" href="https://www.kaggle.com/c/favorita-grocery-sales-forecasting/overview">Corporación Favorita Grocery Sales Forecasting</a> dataset, as demonstrated in the <strong>Favorita Dataset Creation Example</strong> tutorial, which is also part of this documentation.</p>
<p>The training routine implemented below, uses <em>pure</em> pytorch, for clarity purposes. However, it can be easily adapted to frameworks such as <a class="reference external" href="https://pytorch.org/ignite/index.html">pytorch-ignite</a> or <a class="reference external" href="https://www.pytorchlightning.ai/">pytorch-lightning</a> to facilitate, orchestrate, and automate some of the training procedure.</p>
<div class="section" id="Importing-the-required-libraries">
<h2>Importing the required libraries<a class="headerlink" href="#Importing-the-required-libraries" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span><span class="n">List</span><span class="p">,</span><span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span><span class="p">,</span><span class="n">DictConfig</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.init</span> <span class="k">as</span> <span class="nn">init</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="nn">tft_torch.tft</span> <span class="kn">import</span> <span class="n">TemporalFusionTransformer</span>
<span class="kn">import</span> <span class="nn">tft_torch.loss</span> <span class="k">as</span> <span class="nn">tft_loss</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-related">
<h2>Data-related<a class="headerlink" href="#Data-related" title="Permalink to this headline">¶</a></h2>
<p>Setting the path to the location in which we saved the processed dataset in the previous tutorial:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;.../data/favorita/data.pickle&#39;</span>
</pre></div>
</div>
</div>
<p>Reading the pickle we saved, and take a pick at its content:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;data_sets&#39;, &#39;feature_map&#39;, &#39;scalers&#39;, &#39;categorical_cardinalities&#39;]
</pre></div></div>
</div>
<p>Displaying the content of the <code class="docutils literal notranslate"><span class="pre">data_sets</span></code> key. Note that the shapes of the array, in case you follow the previous tutorial, depends on the range of dates configured.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">set_name</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=======&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">set_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=======&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">arr_name</span><span class="p">,</span><span class="n">arr</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="n">set_name</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">arr_name</span><span class="si">}</span><span class="s2"> (shape,dtype)&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
=======
train
=======
time_index (shape,dtype)
(11532481,) object
combination_id (shape,dtype)
(11532481,) &lt;U10
static_feats_numeric (shape,dtype)
(11532481, 0) float32
static_feats_categorical (shape,dtype)
(11532481, 9) int32
historical_ts_numeric (shape,dtype)
(11532481, 90, 4) float32
historical_ts_categorical (shape,dtype)
(11532481, 90, 7) int32
future_ts_numeric (shape,dtype)
(11532481, 30, 1) float32
future_ts_categorical (shape,dtype)
(11532481, 30, 7) int32
target (shape,dtype)
(11532481, 30) float32
=======
validation
=======
time_index (shape,dtype)
(120833,) object
combination_id (shape,dtype)
(120833,) &lt;U10
static_feats_numeric (shape,dtype)
(120833, 0) float32
static_feats_categorical (shape,dtype)
(120833, 9) int32
historical_ts_numeric (shape,dtype)
(120833, 90, 4) float32
historical_ts_categorical (shape,dtype)
(120833, 90, 7) int32
future_ts_numeric (shape,dtype)
(120833, 30, 1) float32
future_ts_categorical (shape,dtype)
(120833, 30, 7) int32
target (shape,dtype)
(120833, 30) float32
=======
test
=======
time_index (shape,dtype)
(3454260,) object
combination_id (shape,dtype)
(3454260,) &lt;U10
static_feats_numeric (shape,dtype)
(3454260, 0) float32
static_feats_categorical (shape,dtype)
(3454260, 9) int32
historical_ts_numeric (shape,dtype)
(3454260, 90, 4) float32
historical_ts_categorical (shape,dtype)
(3454260, 90, 7) int32
future_ts_numeric (shape,dtype)
(3454260, 30, 1) float32
future_ts_categorical (shape,dtype)
(3454260, 30, 7) int32
target (shape,dtype)
(3454260, 30) float32
</pre></div></div>
</div>
<div class="section" id="Modeling-configuration">
<h3>Modeling configuration<a class="headerlink" href="#Modeling-configuration" title="Permalink to this headline">¶</a></h3>
<p>We have some arguments to configure, related to the optimization methodology and to the model structure:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;optimization&#39;</span><span class="p">:</span>
                 <span class="p">{</span>
                     <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;inference&#39;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">},</span>
                     <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
                     <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="p">}</span>
                 <span class="p">,</span>
                 <span class="s1">&#39;model&#39;</span><span class="p">:</span>
                 <span class="p">{</span>
                     <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
                     <span class="s1">&#39;state_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
                     <span class="s1">&#39;output_quantiles&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
                     <span class="s1">&#39;lstm_layers&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="s1">&#39;attention_heads&#39;</span><span class="p">:</span> <span class="mi">4</span>
                 <span class="p">},</span>
                 <span class="c1"># these arguments are related to possible extensions of the model class</span>
                 <span class="s1">&#39;task_type&#39;</span><span class="p">:</span><span class="s1">&#39;regression&#39;</span><span class="p">,</span>
                 <span class="s1">&#39;target_window_start&#39;</span><span class="p">:</span> <span class="kc">None</span>
                <span class="p">}</span>
</pre></div>
</div>
</div>
<p>In addition to the configuration parameters mentioned above, the model also expects the some meta data, specifying the structure of the input, including how many variables compose each input channel, and the cardinalities for the categorical variables (which are required for the embedding layers). The meta data specified above is available as part of the pickle we created when we processed the raw data, so here it comes handy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_map</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;feature_map&#39;</span><span class="p">]</span>
<span class="n">cardinalities_map</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;categorical_cardinalities&#39;</span><span class="p">]</span>

<span class="n">structure</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;num_historical_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_historical_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_static_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_static_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_future_numeric&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_numeric&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;num_future_categorical&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;historical_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]],</span>
    <span class="s1">&#39;static_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]],</span>
    <span class="s1">&#39;future_categorical_cardinalities&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cardinalities_map</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]],</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>Note that we add <code class="docutils literal notranslate"><span class="pre">1</span></code> to each of the categorical cardinalities. The reason for that is that the categorical cardinalities are taken from the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> objects which were used for encoding the data in the processing phase. As these <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> objects were fit to the training subset, some categories that appeared on the later parts of the dataset (validation/test subsets) were possibly unseen by these <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code>s. Hence, the encodings we applied allocated/appended a new label
index for each unseen category, and here we somehow <em>“inform”</em> the model the precise number of categories the model will need to embed for each attribute.</p>
<p>Adding the input structure we inferred to the configuration object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;data_props&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">structure</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Model-Creation-and-Initiation">
<h3>Model Creation and Initiation<a class="headerlink" href="#Model-Creation-and-Initiation" title="Permalink to this headline">¶</a></h3>
<p>The model is initiated by the configuration created above:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TemporalFusionTransformer</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">configuration</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>For initialization of the weights composing the model, we use the legendary <a class="reference external" href="https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5">snippet/gist</a> provided by <a class="reference external" href="https://gist.github.com/jeasinema">jeasinema</a>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">weight_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Usage:</span>
<span class="sd">        model = Model()</span>
<span class="sd">        model.apply(weight_init)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">names</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">_all_weights</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">n</span><span class="p">,</span> <span class="n">names</span><span class="p">):</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span> <span class="o">//</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Then we specify the device, according to the availability of <em>CUDA</em> device, and transfer the model to the device accordingly:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">is_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">is_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now that the model is set, we initalize the optimizer, and point it to the model parameters:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())),</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-Preparation">
<h3>Data Preparation<a class="headerlink" href="#Data-Preparation" title="Permalink to this headline">¶</a></h3>
<p>As a utility class, we will declare <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> which digests a dictionary of numpy arrays, and makes sure that each record/observation that will be retrieved using this dataset, will be output as a dictionary of tensors with keys corresponding to these of the original input dictionary. This <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> be useful because when we’ll wrap it with a dedicated <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> object, our mini-batches will be <code class="docutils literal notranslate"><span class="pre">dict</span></code> objects as well, which is highly convenient. <strong>Note</strong>: The tensor data-types
are set according to the data-type of the corresponding numpy arrays.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">DictDataSet</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">array_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">)):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ByteTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">CharTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int16</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ShortTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">)[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>In addition, we’ll define a function named <code class="docutils literal notranslate"><span class="pre">recycle</span></code>, which will be used for creating some kind of “<em>infinite</em>” data loader, i.e. by wrapping a dataloader with this utility function, we make sure that we’ll be able to get batches (using e.g. <code class="docutils literal notranslate"><span class="pre">next</span></code>), and the iterator won’t get to its ending state.</p>
<p>One last utility data-related utility function is <code class="docutils literal notranslate"><span class="pre">get_set_and_loaders()</span></code>, which expects a <code class="docutils literal notranslate"><span class="pre">dict</span></code> of numpy arrays, transforms it into a <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> object, and creates two data loaders for each set. One data loader will be shuffled and, what was termed as “<em>infinite</em>”, and the second one will be serial, for allowing us to perform inference on all the observations in the dataset, while keeping them in the original order. <em>Note</em>: the input argument <code class="docutils literal notranslate"><span class="pre">ignore_keys</span></code> allows discarding some
keys in the original dictionary, <code class="docutils literal notranslate"><span class="pre">data_dict</span></code>, and not including them in the resulting <code class="docutils literal notranslate"><span class="pre">DictDataSet</span></code> and in the corresponding batches it’ll produce.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">recycle</span><span class="p">(</span><span class="n">iterable</span><span class="p">):</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">get_set_and_loaders</span><span class="p">(</span><span class="n">data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
                        <span class="n">shuffled_loader_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
                        <span class="n">serial_loader_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
                        <span class="n">ignore_keys</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">DictDataSet</span><span class="p">({</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">ignore_keys</span> <span class="ow">and</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore_keys</span><span class="p">)})</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">**</span><span class="n">shuffled_loader_config</span><span class="p">)</span>
    <span class="n">serial_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">**</span><span class="n">serial_loader_config</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span><span class="nb">iter</span><span class="p">(</span><span class="n">recycle</span><span class="p">(</span><span class="n">loader</span><span class="p">)),</span><span class="n">serial_loader</span>
</pre></div>
</div>
</div>
<p>We set the configuration for the shuffled data loaders, and for the serial ones, and we also set the <code class="docutils literal notranslate"><span class="pre">meta_keys</span></code> which specifies which keys do not contain actual data (only meta-data to identify each record):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">shuffled_loader_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;batch_size&#39;</span><span class="p">][</span><span class="s1">&#39;training&#39;</span><span class="p">],</span>
                <span class="s1">&#39;drop_last&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s1">&#39;shuffle&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">}</span>

<span class="n">serial_loader_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;batch_size&#39;</span><span class="p">][</span><span class="s1">&#39;inference&#39;</span><span class="p">],</span>
                <span class="s1">&#39;drop_last&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s1">&#39;shuffle&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">}</span>

<span class="c1"># the following fields do not contain actual data, but are only identifiers of each observation</span>
<span class="n">meta_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;time_index&#39;</span><span class="p">,</span><span class="s1">&#39;combination_id&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>We use the utility functions for generating the required data loaders for each of the subsets:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_set</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">train_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
<span class="n">validation_set</span><span class="p">,</span><span class="n">validation_loader</span><span class="p">,</span><span class="n">validation_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
<span class="n">test_set</span><span class="p">,</span><span class="n">test_loader</span><span class="p">,</span><span class="n">test_serial_loader</span> <span class="o">=</span> <span class="n">get_set_and_loaders</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;test&#39;</span><span class="p">],</span>
                                                                <span class="n">shuffled_loader_config</span><span class="p">,</span>
                                                                <span class="n">serial_loader_config</span><span class="p">,</span>
                                                                <span class="n">ignore_keys</span><span class="o">=</span><span class="n">meta_keys</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-Procedure">
<h3>Training Procedure<a class="headerlink" href="#Training-Procedure" title="Permalink to this headline">¶</a></h3>
<p>Now that everything is set in terms of the model and the data, we define some helpful utilities for easier orchestration of the training procedure.</p>
<p><code class="docutils literal notranslate"><span class="pre">QueueAggregator</span></code> is, well, a queue, which will be used as a running-window aggregator of the training performance metric. We’ll use it to for smoother (and less noisier) estimation of our loss during training.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">QueueAggregator</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span> <span class="o">=</span> <span class="n">max_size</span>

    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elem</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_queued_list</span>
</pre></div>
</div>
</div>
<p>We also employ an <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> mechanism for monitoring the performance on our validation set, and indicate when can we quit training. This extremely <a class="reference external" href="https://gist.github.com/stefanonardo/693d96ceb2f531fa05db530f3e21517d">useful snippet</a> was originally contributed by <a class="reference external" href="https://gist.github.com/stefanonardo">stefanonardo</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">percentage</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_is_better</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">min_delta</span><span class="p">,</span> <span class="n">percentage</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">patience</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">metrics</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bad_epochs</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_init_is_better</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">min_delta</span><span class="p">,</span> <span class="n">percentage</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;mode &#39;</span> <span class="o">+</span> <span class="n">mode</span> <span class="o">+</span> <span class="s1">&#39; is unknown!&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">percentage</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">best</span> <span class="o">-</span> <span class="n">min_delta</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">best</span> <span class="o">+</span> <span class="n">min_delta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">best</span> <span class="o">-</span> <span class="p">(</span>
                            <span class="n">best</span> <span class="o">*</span> <span class="n">min_delta</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_better</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">best</span><span class="p">:</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">best</span> <span class="o">+</span> <span class="p">(</span>
                            <span class="n">best</span> <span class="o">*</span> <span class="n">min_delta</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Training-Settings">
<h2>Training Settings<a class="headerlink" href="#Training-Settings" title="Permalink to this headline">¶</a></h2>
<p>Let’s go over to required parameters which will control the training routine:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># If early stopping is not triggered, after how many epochs should we quit training</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># how many training batches will compose a single training epoch</span>
<span class="n">epoch_iters</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># upon completing a training epoch, we perform an evaluation of all the subsets</span>
<span class="c1"># eval_iters will define how many batches of each set will compose a single evaluation round</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">500</span>
<span class="c1"># during training, on what frequency should we display the monitored performance</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># what is the running-window used by our QueueAggregator object for monitoring the training performance</span>
<span class="n">ma_queue_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># how many evaluation rounds should we allow,</span>
<span class="c1"># without any improvement in the performance observed on the validation set</span>
<span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># initialize early stopping mechanism</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">)</span>
<span class="c1"># initialize the loss aggregator for running window performance estimation</span>
<span class="n">loss_aggregator</span> <span class="o">=</span> <span class="n">QueueAggregator</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">ma_queue_size</span><span class="p">)</span>

<span class="c1"># initialize counters</span>
<span class="n">batch_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epoch_idx</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<p>For computing the loss we are seeking to optimize, we need to define a tensor, corresponding to the actual quantiles we want to estimate:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">quantiles_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;output_quantiles&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The following cell implements the way each batch is processed by our training/evaluation procedure. We transfer each batch component to the <code class="docutils literal notranslate"><span class="pre">device</span></code> we’re using, feed the batch to the model, and compute the loss, using the labels (which are part of our batch), the <code class="docutils literal notranslate"><span class="pre">predicted_quantiles</span></code> output, and the <em>fixed</em> tensor <code class="docutils literal notranslate"><span class="pre">quantiles_tensor</span></code> stating the quantiles we wish to estimate.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">],</span>
                  <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                  <span class="n">quantiles_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                  <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="n">predicted_quantiles</span> <span class="o">=</span> <span class="n">batch_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">]</span>
    <span class="n">q_loss</span><span class="p">,</span> <span class="n">q_risk</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tft_loss</span><span class="o">.</span><span class="n">get_quantiles_loss_and_q_risk</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">predicted_quantiles</span><span class="p">,</span>
                                                              <span class="n">targets</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                                                              <span class="n">desired_quantiles</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">q_loss</span><span class="p">,</span> <span class="n">q_risk</span>
</pre></div>
</div>
</div>
<p>Now, finally, is the actual training loop. This loop will go on until completing <code class="docutils literal notranslate"><span class="pre">max_epoch</span></code> rounds, or until <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> is triggered.</p>
<p>Each epoch starts with the evaluation of each of the subsets. Each evaluation rounds includes the processing of <code class="docutils literal notranslate"><span class="pre">eval_iters</span></code> batches from the relevant subset, after which the losses and the metrics are concatenated and averaged. The loss computed for the validation set is fed to the early stopping mechanism for continuous tracking.</p>
<p>After completing the evaluation of the data subsets, a training round, including the processing of <code class="docutils literal notranslate"><span class="pre">epoch_iters</span></code> batches from the training subset, is initiated. For each training batch, the computed loss is used for calling the optimizer to update the model weights, and added to the loss aggregator.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">while</span> <span class="n">epoch_idx</span> <span class="o">&lt;</span> <span class="n">max_epochs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting Epoch Index </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># evaluation round</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># for each subset</span>
        <span class="k">for</span> <span class="n">subset_name</span><span class="p">,</span> <span class="n">subset_loader</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="s1">&#39;validation&#39;</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">],[</span><span class="n">train_loader</span><span class="p">,</span><span class="n">validation_loader</span><span class="p">,</span><span class="n">test_loader</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluating </span><span class="si">{</span><span class="n">subset_name</span><span class="si">}</span><span class="s2"> set&quot;</span><span class="p">)</span>

            <span class="n">q_loss_vals</span><span class="p">,</span> <span class="n">q_risk_vals</span> <span class="o">=</span> <span class="p">[],[]</span> <span class="c1"># used for aggregating performance along the evaluation round</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
                <span class="c1"># get batch</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">subset_loader</span><span class="p">)</span>
                <span class="c1"># process batch</span>
                <span class="n">batch_loss</span><span class="p">,</span><span class="n">batch_q_risk</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">quantiles_tensor</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># accumulate performance</span>
                <span class="n">q_loss_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
                <span class="n">q_risk_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_q_risk</span><span class="p">)</span>

            <span class="c1"># aggregate and average</span>
            <span class="n">eval_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">q_loss_vals</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">eval_q_risk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">q_risk_vals</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># keep for feeding the early stopping mechanism</span>
            <span class="k">if</span> <span class="n">subset_name</span> <span class="o">==</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span>
                <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">eval_loss</span>

            <span class="c1"># log performance</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">, Batch Index: </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="o">+</span> \
                  <span class="sa">f</span><span class="s2">&quot;- Eval </span><span class="si">{</span><span class="n">subset_name</span><span class="si">}</span><span class="s2"> - &quot;</span> <span class="o">+</span> \
                  <span class="sa">f</span><span class="s2">&quot;q_loss = </span><span class="si">{</span><span class="n">eval_loss</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> , &quot;</span> <span class="o">+</span> \
                  <span class="s2">&quot; , &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;q_risk_</span><span class="si">{</span><span class="n">q</span><span class="si">:</span><span class="s2">.1</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">risk</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span><span class="n">risk</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">quantiles_tensor</span><span class="p">,</span><span class="n">eval_q_risk</span><span class="p">)]))</span>

    <span class="c1"># switch to training mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># update early stopping mechanism and stop if triggered</span>
    <span class="k">if</span> <span class="n">es</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Performing early stopping...!&#39;</span><span class="p">)</span>
        <span class="k">break</span>

    <span class="c1"># initiating a training round</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_iters</span><span class="p">):</span>
        <span class="c1"># get training batch</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># process batch</span>
        <span class="n">loss</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">process_batch</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                              <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                              <span class="n">quantiles_tensor</span><span class="o">=</span><span class="n">quantiles_tensor</span><span class="p">,</span>
                              <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># compute gradients</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># gradient clipping</span>
        <span class="k">if</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;max_grad_norm&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;optimization&#39;</span><span class="p">][</span><span class="s1">&#39;max_grad_norm&#39;</span><span class="p">])</span>
        <span class="c1"># update weights</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># accumulate performance</span>
        <span class="n">loss_aggregator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># log performance</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_idx</span><span class="si">}</span><span class="s2">, Batch Index: </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s2"> - Train Loss = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_aggregator</span><span class="o">.</span><span class="n">get</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># completed batch</span>
        <span class="n">batch_idx</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># completed epoch</span>
    <span class="n">epoch_idx</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Starting Epoch Index 0
Evaluating train set
Epoch: 0, Batch Index: 0- Eval train - q_loss = 4.75915 , q_risk_0.1 = 0.99406 , q_risk_0.5 = 5.24727 , q_risk_0.9 = 5.65399
Evaluating validation set
Epoch: 0, Batch Index: 0- Eval validation - q_loss = 4.44160 , q_risk_0.1 = 1.30954 , q_risk_0.5 = 4.96685 , q_risk_0.9 = 4.80658
Evaluating test set
Epoch: 0, Batch Index: 0- Eval test - q_loss = 4.73196 , q_risk_0.1 = 1.01745 , q_risk_0.5 = 5.26701 , q_risk_0.9 = 5.63625
Epoch: 0, Batch Index: 0 - Train Loss = 4.66927433013916
Epoch: 0, Batch Index: 20 - Train Loss = 1.0521832619394575
Epoch: 0, Batch Index: 40 - Train Loss = 0.8945479901825509
Epoch: 0, Batch Index: 60 - Train Loss = 0.6945045125484467
Epoch: 0, Batch Index: 80 - Train Loss = 0.5805041736364365
Epoch: 0, Batch Index: 100 - Train Loss = 0.47956503987312316
Epoch: 0, Batch Index: 120 - Train Loss = 0.44512289881706235
Epoch: 0, Batch Index: 140 - Train Loss = 0.43657967865467073
Epoch: 0, Batch Index: 160 - Train Loss = 0.43277322471141816
Epoch: 0, Batch Index: 180 - Train Loss = 0.4300243490934372
Starting Epoch Index 1
Evaluating train set
Epoch: 1, Batch Index: 200- Eval train - q_loss = 0.42119 , q_risk_0.1 = 0.23783 , q_risk_0.5 = 0.56433 , q_risk_0.9 = 0.25289
Evaluating validation set
Epoch: 1, Batch Index: 200- Eval validation - q_loss = 0.39644 , q_risk_0.1 = 0.20664 , q_risk_0.5 = 0.53696 , q_risk_0.9 = 0.24588
Evaluating test set
Epoch: 1, Batch Index: 200- Eval test - q_loss = 0.42955 , q_risk_0.1 = 0.23951 , q_risk_0.5 = 0.58015 , q_risk_0.9 = 0.26477
Epoch: 1, Batch Index: 200 - Train Loss = 0.4291575014591217
Epoch: 1, Batch Index: 220 - Train Loss = 0.4289798820018768
Epoch: 1, Batch Index: 240 - Train Loss = 0.4247819995880127
Epoch: 1, Batch Index: 260 - Train Loss = 0.422557852268219
Epoch: 1, Batch Index: 280 - Train Loss = 0.42105342030525206
Epoch: 1, Batch Index: 300 - Train Loss = 0.4197930932044983
Epoch: 1, Batch Index: 320 - Train Loss = 0.4200589936971664
Epoch: 1, Batch Index: 340 - Train Loss = 0.420873789191246
Epoch: 1, Batch Index: 360 - Train Loss = 0.42105056166648863
Epoch: 1, Batch Index: 380 - Train Loss = 0.4210237944126129
Starting Epoch Index 2
Evaluating train set
Epoch: 2, Batch Index: 400- Eval train - q_loss = 0.41435 , q_risk_0.1 = 0.23209 , q_risk_0.5 = 0.55826 , q_risk_0.9 = 0.24767
Evaluating validation set
Epoch: 2, Batch Index: 400- Eval validation - q_loss = 0.38803 , q_risk_0.1 = 0.20128 , q_risk_0.5 = 0.52819 , q_risk_0.9 = 0.23997
Evaluating test set
Epoch: 2, Batch Index: 400- Eval test - q_loss = 0.42292 , q_risk_0.1 = 0.23417 , q_risk_0.5 = 0.57305 , q_risk_0.9 = 0.25952
Epoch: 2, Batch Index: 400 - Train Loss = 0.4210153156518936
Epoch: 2, Batch Index: 420 - Train Loss = 0.4189212042093277
Epoch: 2, Batch Index: 440 - Train Loss = 0.41659194707870484
Epoch: 2, Batch Index: 460 - Train Loss = 0.4149512857198715
Epoch: 2, Batch Index: 480 - Train Loss = 0.41588978230953216
Epoch: 2, Batch Index: 500 - Train Loss = 0.4137861984968185
Epoch: 2, Batch Index: 520 - Train Loss = 0.4129298210144043
Epoch: 2, Batch Index: 540 - Train Loss = 0.4143876898288727
Epoch: 2, Batch Index: 560 - Train Loss = 0.4138409286737442
Epoch: 2, Batch Index: 580 - Train Loss = 0.4144619935750961
Starting Epoch Index 3
Evaluating train set
Epoch: 3, Batch Index: 600- Eval train - q_loss = 0.41011 , q_risk_0.1 = 0.23068 , q_risk_0.5 = 0.55093 , q_risk_0.9 = 0.24402
Evaluating validation set
Epoch: 3, Batch Index: 600- Eval validation - q_loss = 0.38626 , q_risk_0.1 = 0.20054 , q_risk_0.5 = 0.52504 , q_risk_0.9 = 0.23911
Evaluating test set
Epoch: 3, Batch Index: 600- Eval test - q_loss = 0.42051 , q_risk_0.1 = 0.23451 , q_risk_0.5 = 0.56814 , q_risk_0.9 = 0.25691
Epoch: 3, Batch Index: 600 - Train Loss = 0.4129968386888504
Epoch: 3, Batch Index: 620 - Train Loss = 0.4115611207485199
Epoch: 3, Batch Index: 640 - Train Loss = 0.41071336388587953
Epoch: 3, Batch Index: 660 - Train Loss = 0.4112099415063858
Epoch: 3, Batch Index: 680 - Train Loss = 0.4097777634859085
Epoch: 3, Batch Index: 700 - Train Loss = 0.41104889452457427
Epoch: 3, Batch Index: 720 - Train Loss = 0.41096755385398864
Epoch: 3, Batch Index: 740 - Train Loss = 0.41224782168865204
Epoch: 3, Batch Index: 760 - Train Loss = 0.4109210765361786
Epoch: 3, Batch Index: 780 - Train Loss = 0.4092313438653946
Starting Epoch Index 4
Evaluating train set
Epoch: 4, Batch Index: 800- Eval train - q_loss = 0.40724 , q_risk_0.1 = 0.23008 , q_risk_0.5 = 0.54588 , q_risk_0.9 = 0.24148
Evaluating validation set
Epoch: 4, Batch Index: 800- Eval validation - q_loss = 0.38552 , q_risk_0.1 = 0.20152 , q_risk_0.5 = 0.52156 , q_risk_0.9 = 0.23887
Evaluating test set
Epoch: 4, Batch Index: 800- Eval test - q_loss = 0.41886 , q_risk_0.1 = 0.23383 , q_risk_0.5 = 0.56683 , q_risk_0.9 = 0.25698
Epoch: 4, Batch Index: 800 - Train Loss = 0.4098439073562622
Epoch: 4, Batch Index: 820 - Train Loss = 0.4111397838592529
Epoch: 4, Batch Index: 840 - Train Loss = 0.40885140478610993
Epoch: 4, Batch Index: 860 - Train Loss = 0.40637300789356234
Epoch: 4, Batch Index: 880 - Train Loss = 0.40647446513175967
Epoch: 4, Batch Index: 900 - Train Loss = 0.40709618031978606
Epoch: 4, Batch Index: 920 - Train Loss = 0.4072889602184296
Epoch: 4, Batch Index: 940 - Train Loss = 0.40552869021892546
Epoch: 4, Batch Index: 960 - Train Loss = 0.40506561458110807
Epoch: 4, Batch Index: 980 - Train Loss = 0.40491498172283175
Starting Epoch Index 5
Evaluating train set
Epoch: 5, Batch Index: 1000- Eval train - q_loss = 0.40285 , q_risk_0.1 = 0.22529 , q_risk_0.5 = 0.54457 , q_risk_0.9 = 0.23957
Evaluating validation set
Epoch: 5, Batch Index: 1000- Eval validation - q_loss = 0.37814 , q_risk_0.1 = 0.19418 , q_risk_0.5 = 0.51587 , q_risk_0.9 = 0.23468
Evaluating test set
Epoch: 5, Batch Index: 1000- Eval test - q_loss = 0.41239 , q_risk_0.1 = 0.22769 , q_risk_0.5 = 0.56062 , q_risk_0.9 = 0.25132
Epoch: 5, Batch Index: 1000 - Train Loss = 0.4049234038591385
Epoch: 5, Batch Index: 1020 - Train Loss = 0.4038917464017868
Epoch: 5, Batch Index: 1040 - Train Loss = 0.40648993372917175
Epoch: 5, Batch Index: 1060 - Train Loss = 0.4073482412099838
Epoch: 5, Batch Index: 1080 - Train Loss = 0.4067541301250458
Epoch: 5, Batch Index: 1100 - Train Loss = 0.4047557181119919
Epoch: 5, Batch Index: 1120 - Train Loss = 0.40506629168987274
Epoch: 5, Batch Index: 1140 - Train Loss = 0.40554743468761445
Epoch: 5, Batch Index: 1160 - Train Loss = 0.40521927118301393
Epoch: 5, Batch Index: 1180 - Train Loss = 0.405349937081337
Starting Epoch Index 6
Evaluating train set
Epoch: 6, Batch Index: 1200- Eval train - q_loss = 0.40149 , q_risk_0.1 = 0.22378 , q_risk_0.5 = 0.54149 , q_risk_0.9 = 0.23779
Evaluating validation set
Epoch: 6, Batch Index: 1200- Eval validation - q_loss = 0.37858 , q_risk_0.1 = 0.19424 , q_risk_0.5 = 0.51572 , q_risk_0.9 = 0.23359
Evaluating test set
Epoch: 6, Batch Index: 1200- Eval test - q_loss = 0.41150 , q_risk_0.1 = 0.22719 , q_risk_0.5 = 0.56113 , q_risk_0.9 = 0.25104
Epoch: 6, Batch Index: 1200 - Train Loss = 0.4040474933385849
Epoch: 6, Batch Index: 1220 - Train Loss = 0.4059846353530884
Epoch: 6, Batch Index: 1240 - Train Loss = 0.4079109823703766
Epoch: 6, Batch Index: 1260 - Train Loss = 0.40785058557987214
Epoch: 6, Batch Index: 1280 - Train Loss = 0.4041638249158859
Epoch: 6, Batch Index: 1300 - Train Loss = 0.4042203724384308
Epoch: 6, Batch Index: 1320 - Train Loss = 0.4061504632234573
Epoch: 6, Batch Index: 1340 - Train Loss = 0.40467872202396393
Epoch: 6, Batch Index: 1360 - Train Loss = 0.4037921714782715
Epoch: 6, Batch Index: 1380 - Train Loss = 0.40475361704826357
Starting Epoch Index 7
Evaluating train set
Epoch: 7, Batch Index: 1400- Eval train - q_loss = 0.40373 , q_risk_0.1 = 0.22755 , q_risk_0.5 = 0.54572 , q_risk_0.9 = 0.23794
Evaluating validation set
Epoch: 7, Batch Index: 1400- Eval validation - q_loss = 0.38025 , q_risk_0.1 = 0.19694 , q_risk_0.5 = 0.51909 , q_risk_0.9 = 0.23403
Evaluating test set
Epoch: 7, Batch Index: 1400- Eval test - q_loss = 0.41171 , q_risk_0.1 = 0.22957 , q_risk_0.5 = 0.56143 , q_risk_0.9 = 0.24967
Epoch: 7, Batch Index: 1400 - Train Loss = 0.40537675201892853
Epoch: 7, Batch Index: 1420 - Train Loss = 0.4036330646276474
Epoch: 7, Batch Index: 1440 - Train Loss = 0.40228052258491515
Epoch: 7, Batch Index: 1460 - Train Loss = 0.40184262812137606
Epoch: 7, Batch Index: 1480 - Train Loss = 0.4016137725114822
Epoch: 7, Batch Index: 1500 - Train Loss = 0.40090774953365327
Epoch: 7, Batch Index: 1520 - Train Loss = 0.40151053309440615
Epoch: 7, Batch Index: 1540 - Train Loss = 0.4007548987865448
Epoch: 7, Batch Index: 1560 - Train Loss = 0.4018117582798004
Epoch: 7, Batch Index: 1580 - Train Loss = 0.4014294320344925
Starting Epoch Index 8
Evaluating train set
Epoch: 8, Batch Index: 1600- Eval train - q_loss = 0.39870 , q_risk_0.1 = 0.22328 , q_risk_0.5 = 0.53851 , q_risk_0.9 = 0.23663
Evaluating validation set
Epoch: 8, Batch Index: 1600- Eval validation - q_loss = 0.37515 , q_risk_0.1 = 0.19362 , q_risk_0.5 = 0.51104 , q_risk_0.9 = 0.23240
Evaluating test set
Epoch: 8, Batch Index: 1600- Eval test - q_loss = 0.40761 , q_risk_0.1 = 0.22673 , q_risk_0.5 = 0.55586 , q_risk_0.9 = 0.24830
Epoch: 8, Batch Index: 1600 - Train Loss = 0.4001636624336243
Epoch: 8, Batch Index: 1620 - Train Loss = 0.402531630396843
Epoch: 8, Batch Index: 1640 - Train Loss = 0.4018902719020844
Epoch: 8, Batch Index: 1660 - Train Loss = 0.4020980644226074
Epoch: 8, Batch Index: 1680 - Train Loss = 0.40103001773357394
Epoch: 8, Batch Index: 1700 - Train Loss = 0.40055160284042357
Epoch: 8, Batch Index: 1720 - Train Loss = 0.3993692350387573
Epoch: 8, Batch Index: 1740 - Train Loss = 0.40109665870666505
Epoch: 8, Batch Index: 1760 - Train Loss = 0.40211093068122866
Epoch: 8, Batch Index: 1780 - Train Loss = 0.40189853966236117
Starting Epoch Index 9
Evaluating train set
Epoch: 9, Batch Index: 1800- Eval train - q_loss = 0.39920 , q_risk_0.1 = 0.22230 , q_risk_0.5 = 0.53801 , q_risk_0.9 = 0.23829
Evaluating validation set
Epoch: 9, Batch Index: 1800- Eval validation - q_loss = 0.37474 , q_risk_0.1 = 0.19158 , q_risk_0.5 = 0.51036 , q_risk_0.9 = 0.23384
Evaluating test set
Epoch: 9, Batch Index: 1800- Eval test - q_loss = 0.40803 , q_risk_0.1 = 0.22489 , q_risk_0.5 = 0.55457 , q_risk_0.9 = 0.25024
Epoch: 9, Batch Index: 1800 - Train Loss = 0.39986729085445405
Epoch: 9, Batch Index: 1820 - Train Loss = 0.4002132898569107
Epoch: 9, Batch Index: 1840 - Train Loss = 0.4008748996257782
Epoch: 9, Batch Index: 1860 - Train Loss = 0.4020387351512909
Epoch: 9, Batch Index: 1880 - Train Loss = 0.40122935593128206
Epoch: 9, Batch Index: 1900 - Train Loss = 0.3988254433870316
Epoch: 9, Batch Index: 1920 - Train Loss = 0.3979205828905106
Epoch: 9, Batch Index: 1940 - Train Loss = 0.3984724915027618
Epoch: 9, Batch Index: 1960 - Train Loss = 0.399396493434906
Epoch: 9, Batch Index: 1980 - Train Loss = 0.4007228797674179
Starting Epoch Index 10
Evaluating train set
Epoch: 10, Batch Index: 2000- Eval train - q_loss = 0.39782 , q_risk_0.1 = 0.22145 , q_risk_0.5 = 0.53674 , q_risk_0.9 = 0.23643
Evaluating validation set
Epoch: 10, Batch Index: 2000- Eval validation - q_loss = 0.37595 , q_risk_0.1 = 0.19210 , q_risk_0.5 = 0.51133 , q_risk_0.9 = 0.23403
Evaluating test set
Epoch: 10, Batch Index: 2000- Eval test - q_loss = 0.40820 , q_risk_0.1 = 0.22578 , q_risk_0.5 = 0.55544 , q_risk_0.9 = 0.24779
Epoch: 10, Batch Index: 2000 - Train Loss = 0.3978684228658676
Epoch: 10, Batch Index: 2020 - Train Loss = 0.39636427819728853
Epoch: 10, Batch Index: 2040 - Train Loss = 0.3968904310464859
Epoch: 10, Batch Index: 2060 - Train Loss = 0.4009086382389069
Epoch: 10, Batch Index: 2080 - Train Loss = 0.3991157466173172
Epoch: 10, Batch Index: 2100 - Train Loss = 0.39911109924316407
Epoch: 10, Batch Index: 2120 - Train Loss = 0.39959205031394956
Epoch: 10, Batch Index: 2140 - Train Loss = 0.3999785673618317
Epoch: 10, Batch Index: 2160 - Train Loss = 0.4003705686330795
Epoch: 10, Batch Index: 2180 - Train Loss = 0.39992914617061615
Starting Epoch Index 11
Evaluating train set
Epoch: 11, Batch Index: 2200- Eval train - q_loss = 0.39759 , q_risk_0.1 = 0.22179 , q_risk_0.5 = 0.53600 , q_risk_0.9 = 0.23777
Evaluating validation set
Epoch: 11, Batch Index: 2200- Eval validation - q_loss = 0.37405 , q_risk_0.1 = 0.19157 , q_risk_0.5 = 0.50861 , q_risk_0.9 = 0.23412
Evaluating test set
Epoch: 11, Batch Index: 2200- Eval test - q_loss = 0.40727 , q_risk_0.1 = 0.22470 , q_risk_0.5 = 0.55310 , q_risk_0.9 = 0.25096
Epoch: 11, Batch Index: 2200 - Train Loss = 0.39871573507785796
Epoch: 11, Batch Index: 2220 - Train Loss = 0.3969588357210159
Epoch: 11, Batch Index: 2240 - Train Loss = 0.39819719195365905
Epoch: 11, Batch Index: 2260 - Train Loss = 0.39947281301021575
Epoch: 11, Batch Index: 2280 - Train Loss = 0.399673810005188
Epoch: 11, Batch Index: 2300 - Train Loss = 0.39861518383026123
Epoch: 11, Batch Index: 2320 - Train Loss = 0.39891193091869354
Epoch: 11, Batch Index: 2340 - Train Loss = 0.3982319062948227
Epoch: 11, Batch Index: 2360 - Train Loss = 0.39839876055717466
Epoch: 11, Batch Index: 2380 - Train Loss = 0.3981969475746155
Starting Epoch Index 12
Evaluating train set
Epoch: 12, Batch Index: 2400- Eval train - q_loss = 0.39648 , q_risk_0.1 = 0.22147 , q_risk_0.5 = 0.53548 , q_risk_0.9 = 0.23572
Evaluating validation set
Epoch: 12, Batch Index: 2400- Eval validation - q_loss = 0.37261 , q_risk_0.1 = 0.19107 , q_risk_0.5 = 0.50719 , q_risk_0.9 = 0.23163
Evaluating test set
Epoch: 12, Batch Index: 2400- Eval test - q_loss = 0.40608 , q_risk_0.1 = 0.22486 , q_risk_0.5 = 0.55355 , q_risk_0.9 = 0.24840
Epoch: 12, Batch Index: 2400 - Train Loss = 0.39700213134288787
Epoch: 12, Batch Index: 2420 - Train Loss = 0.39765942096710205
Epoch: 12, Batch Index: 2440 - Train Loss = 0.39903940677642824
Epoch: 12, Batch Index: 2460 - Train Loss = 0.39798458218574523
Epoch: 12, Batch Index: 2480 - Train Loss = 0.397613610625267
Epoch: 12, Batch Index: 2500 - Train Loss = 0.39643609166145327
Epoch: 12, Batch Index: 2520 - Train Loss = 0.39598207890987397
Epoch: 12, Batch Index: 2540 - Train Loss = 0.3954656547307968
Epoch: 12, Batch Index: 2560 - Train Loss = 0.3967180019617081
Epoch: 12, Batch Index: 2580 - Train Loss = 0.396728892326355
Starting Epoch Index 13
Evaluating train set
Epoch: 13, Batch Index: 2600- Eval train - q_loss = 0.39918 , q_risk_0.1 = 0.22127 , q_risk_0.5 = 0.53792 , q_risk_0.9 = 0.24182
Evaluating validation set
Epoch: 13, Batch Index: 2600- Eval validation - q_loss = 0.37315 , q_risk_0.1 = 0.19084 , q_risk_0.5 = 0.50678 , q_risk_0.9 = 0.23426
Evaluating test set
Epoch: 13, Batch Index: 2600- Eval test - q_loss = 0.40905 , q_risk_0.1 = 0.22486 , q_risk_0.5 = 0.55634 , q_risk_0.9 = 0.25211
Epoch: 13, Batch Index: 2600 - Train Loss = 0.3966806316375732
Epoch: 13, Batch Index: 2620 - Train Loss = 0.3976715445518494
Epoch: 13, Batch Index: 2640 - Train Loss = 0.39764769971370695
Epoch: 13, Batch Index: 2660 - Train Loss = 0.39680090606212615
Epoch: 13, Batch Index: 2680 - Train Loss = 0.3968888396024704
Epoch: 13, Batch Index: 2700 - Train Loss = 0.3964542716741562
Epoch: 13, Batch Index: 2720 - Train Loss = 0.39596045613288877
Epoch: 13, Batch Index: 2740 - Train Loss = 0.396104519367218
Epoch: 13, Batch Index: 2760 - Train Loss = 0.3982889896631241
Epoch: 13, Batch Index: 2780 - Train Loss = 0.39781312346458436
Starting Epoch Index 14
Evaluating train set
Epoch: 14, Batch Index: 2800- Eval train - q_loss = 0.39459 , q_risk_0.1 = 0.21958 , q_risk_0.5 = 0.53471 , q_risk_0.9 = 0.23340
Evaluating validation set
Epoch: 14, Batch Index: 2800- Eval validation - q_loss = 0.37265 , q_risk_0.1 = 0.19029 , q_risk_0.5 = 0.50932 , q_risk_0.9 = 0.23040
Evaluating test set
Epoch: 14, Batch Index: 2800- Eval test - q_loss = 0.40523 , q_risk_0.1 = 0.22327 , q_risk_0.5 = 0.55291 , q_risk_0.9 = 0.24564
Epoch: 14, Batch Index: 2800 - Train Loss = 0.39781020700931546
Epoch: 14, Batch Index: 2820 - Train Loss = 0.3970323467254639
Epoch: 14, Batch Index: 2840 - Train Loss = 0.3976580572128296
Epoch: 14, Batch Index: 2860 - Train Loss = 0.3979163783788681
Epoch: 14, Batch Index: 2880 - Train Loss = 0.39644902646541597
Epoch: 14, Batch Index: 2900 - Train Loss = 0.3950371038913727
Epoch: 14, Batch Index: 2920 - Train Loss = 0.3952718794345856
Epoch: 14, Batch Index: 2940 - Train Loss = 0.39541137516498565
Epoch: 14, Batch Index: 2960 - Train Loss = 0.3969502729177475
Epoch: 14, Batch Index: 2980 - Train Loss = 0.395832467675209
Starting Epoch Index 15
Evaluating train set
Epoch: 15, Batch Index: 3000- Eval train - q_loss = 0.39714 , q_risk_0.1 = 0.22226 , q_risk_0.5 = 0.53828 , q_risk_0.9 = 0.23498
Evaluating validation set
Epoch: 15, Batch Index: 3000- Eval validation - q_loss = 0.37393 , q_risk_0.1 = 0.19294 , q_risk_0.5 = 0.50958 , q_risk_0.9 = 0.23140
Evaluating test set
Epoch: 15, Batch Index: 3000- Eval test - q_loss = 0.40615 , q_risk_0.1 = 0.22605 , q_risk_0.5 = 0.55398 , q_risk_0.9 = 0.24582
Epoch: 15, Batch Index: 3000 - Train Loss = 0.39729693353176115
Epoch: 15, Batch Index: 3020 - Train Loss = 0.3953527402877808
Epoch: 15, Batch Index: 3040 - Train Loss = 0.39543473958969116
Epoch: 15, Batch Index: 3060 - Train Loss = 0.39728510737419126
Epoch: 15, Batch Index: 3080 - Train Loss = 0.3964095360040665
Epoch: 15, Batch Index: 3100 - Train Loss = 0.3949676764011383
Epoch: 15, Batch Index: 3120 - Train Loss = 0.39480706870555876
Epoch: 15, Batch Index: 3140 - Train Loss = 0.39660423576831816
Epoch: 15, Batch Index: 3160 - Train Loss = 0.3972543615102768
Epoch: 15, Batch Index: 3180 - Train Loss = 0.3973347496986389
Starting Epoch Index 16
Evaluating train set
Epoch: 16, Batch Index: 3200- Eval train - q_loss = 0.39444 , q_risk_0.1 = 0.22006 , q_risk_0.5 = 0.53245 , q_risk_0.9 = 0.23348
Evaluating validation set
Epoch: 16, Batch Index: 3200- Eval validation - q_loss = 0.37056 , q_risk_0.1 = 0.19027 , q_risk_0.5 = 0.50439 , q_risk_0.9 = 0.23050
Evaluating test set
Epoch: 16, Batch Index: 3200- Eval test - q_loss = 0.40432 , q_risk_0.1 = 0.22438 , q_risk_0.5 = 0.55182 , q_risk_0.9 = 0.24529
Epoch: 16, Batch Index: 3200 - Train Loss = 0.3976605349779129
Epoch: 16, Batch Index: 3220 - Train Loss = 0.3970503634214401
Epoch: 16, Batch Index: 3240 - Train Loss = 0.39523290932178495
Epoch: 16, Batch Index: 3260 - Train Loss = 0.3957459741830826
Epoch: 16, Batch Index: 3280 - Train Loss = 0.39595109343528745
Epoch: 16, Batch Index: 3300 - Train Loss = 0.39534760773181915
Epoch: 16, Batch Index: 3320 - Train Loss = 0.3953301995992661
Epoch: 16, Batch Index: 3340 - Train Loss = 0.3961678123474121
Epoch: 16, Batch Index: 3360 - Train Loss = 0.39681501030921934
Epoch: 16, Batch Index: 3380 - Train Loss = 0.39666997492313383
Starting Epoch Index 17
Evaluating train set
Epoch: 17, Batch Index: 3400- Eval train - q_loss = 0.39394 , q_risk_0.1 = 0.21933 , q_risk_0.5 = 0.53594 , q_risk_0.9 = 0.23414
Evaluating validation set
Epoch: 17, Batch Index: 3400- Eval validation - q_loss = 0.37085 , q_risk_0.1 = 0.18875 , q_risk_0.5 = 0.50645 , q_risk_0.9 = 0.23074
Evaluating test set
Epoch: 17, Batch Index: 3400- Eval test - q_loss = 0.40370 , q_risk_0.1 = 0.22256 , q_risk_0.5 = 0.55100 , q_risk_0.9 = 0.24437
Epoch: 17, Batch Index: 3400 - Train Loss = 0.3951510202884674
Epoch: 17, Batch Index: 3420 - Train Loss = 0.39481020510196685
Epoch: 17, Batch Index: 3440 - Train Loss = 0.39685794949531555
Epoch: 17, Batch Index: 3460 - Train Loss = 0.3969962054491043
Epoch: 17, Batch Index: 3480 - Train Loss = 0.39576318621635437
Epoch: 17, Batch Index: 3500 - Train Loss = 0.3938006198406219
Epoch: 17, Batch Index: 3520 - Train Loss = 0.39380306243896485
Epoch: 17, Batch Index: 3540 - Train Loss = 0.39310498774051666
Epoch: 17, Batch Index: 3560 - Train Loss = 0.3940486723184586
Epoch: 17, Batch Index: 3580 - Train Loss = 0.39699562191963195
Starting Epoch Index 18
Evaluating train set
Epoch: 18, Batch Index: 3600- Eval train - q_loss = 0.39320 , q_risk_0.1 = 0.21930 , q_risk_0.5 = 0.53239 , q_risk_0.9 = 0.23271
Evaluating validation set
Epoch: 18, Batch Index: 3600- Eval validation - q_loss = 0.37110 , q_risk_0.1 = 0.18884 , q_risk_0.5 = 0.50648 , q_risk_0.9 = 0.23068
Evaluating test set
Epoch: 18, Batch Index: 3600- Eval test - q_loss = 0.40298 , q_risk_0.1 = 0.22199 , q_risk_0.5 = 0.54801 , q_risk_0.9 = 0.24383
Epoch: 18, Batch Index: 3600 - Train Loss = 0.39635176420211793
Epoch: 18, Batch Index: 3620 - Train Loss = 0.3960028713941574
Epoch: 18, Batch Index: 3640 - Train Loss = 0.39506037056446075
Epoch: 18, Batch Index: 3660 - Train Loss = 0.39451864957809446
Epoch: 18, Batch Index: 3680 - Train Loss = 0.39512339770793914
Epoch: 18, Batch Index: 3700 - Train Loss = 0.3953096389770508
Epoch: 18, Batch Index: 3720 - Train Loss = 0.39537117958068846
Epoch: 18, Batch Index: 3740 - Train Loss = 0.3953193271160126
Epoch: 18, Batch Index: 3760 - Train Loss = 0.39490626692771913
Epoch: 18, Batch Index: 3780 - Train Loss = 0.39355007946491244
Starting Epoch Index 19
Evaluating train set
Epoch: 19, Batch Index: 3800- Eval train - q_loss = 0.39362 , q_risk_0.1 = 0.22018 , q_risk_0.5 = 0.53035 , q_risk_0.9 = 0.23264
Evaluating validation set
Epoch: 19, Batch Index: 3800- Eval validation - q_loss = 0.37105 , q_risk_0.1 = 0.19034 , q_risk_0.5 = 0.50554 , q_risk_0.9 = 0.23033
Evaluating test set
Epoch: 19, Batch Index: 3800- Eval test - q_loss = 0.40334 , q_risk_0.1 = 0.22296 , q_risk_0.5 = 0.54867 , q_risk_0.9 = 0.24483
Epoch: 19, Batch Index: 3800 - Train Loss = 0.39333644151687625
Epoch: 19, Batch Index: 3820 - Train Loss = 0.3949238103628159
Epoch: 19, Batch Index: 3840 - Train Loss = 0.39437033116817477
Epoch: 19, Batch Index: 3860 - Train Loss = 0.3927281653881073
Epoch: 19, Batch Index: 3880 - Train Loss = 0.39124185919761656
Epoch: 19, Batch Index: 3900 - Train Loss = 0.39251892745494843
Epoch: 19, Batch Index: 3920 - Train Loss = 0.3932281178236008
Epoch: 19, Batch Index: 3940 - Train Loss = 0.3934887647628784
Epoch: 19, Batch Index: 3960 - Train Loss = 0.3934726893901825
Epoch: 19, Batch Index: 3980 - Train Loss = 0.3949046778678894
Starting Epoch Index 20
Evaluating train set
Epoch: 20, Batch Index: 4000- Eval train - q_loss = 0.39285 , q_risk_0.1 = 0.22023 , q_risk_0.5 = 0.53179 , q_risk_0.9 = 0.23397
Evaluating validation set
Epoch: 20, Batch Index: 4000- Eval validation - q_loss = 0.37006 , q_risk_0.1 = 0.19075 , q_risk_0.5 = 0.50233 , q_risk_0.9 = 0.23014
Evaluating test set
Epoch: 20, Batch Index: 4000- Eval test - q_loss = 0.40337 , q_risk_0.1 = 0.22345 , q_risk_0.5 = 0.54822 , q_risk_0.9 = 0.24455
Epoch: 20, Batch Index: 4000 - Train Loss = 0.3945586884021759
Epoch: 20, Batch Index: 4020 - Train Loss = 0.39419933676719665
Epoch: 20, Batch Index: 4040 - Train Loss = 0.39146160364151
Epoch: 20, Batch Index: 4060 - Train Loss = 0.39218677997589113
Epoch: 20, Batch Index: 4080 - Train Loss = 0.39360586762428285
Epoch: 20, Batch Index: 4100 - Train Loss = 0.3947985363006592
Epoch: 20, Batch Index: 4120 - Train Loss = 0.3937856900691986
Epoch: 20, Batch Index: 4140 - Train Loss = 0.3925702440738678
Epoch: 20, Batch Index: 4160 - Train Loss = 0.39338229298591615
Epoch: 20, Batch Index: 4180 - Train Loss = 0.3949913722276688
Starting Epoch Index 21
Evaluating train set
Epoch: 21, Batch Index: 4200- Eval train - q_loss = 0.39360 , q_risk_0.1 = 0.22118 , q_risk_0.5 = 0.53012 , q_risk_0.9 = 0.23218
Evaluating validation set
Epoch: 21, Batch Index: 4200- Eval validation - q_loss = 0.37120 , q_risk_0.1 = 0.19289 , q_risk_0.5 = 0.50446 , q_risk_0.9 = 0.23015
Evaluating test set
Epoch: 21, Batch Index: 4200- Eval test - q_loss = 0.40400 , q_risk_0.1 = 0.22558 , q_risk_0.5 = 0.54942 , q_risk_0.9 = 0.24486
Epoch: 21, Batch Index: 4200 - Train Loss = 0.39426637411117554
Epoch: 21, Batch Index: 4220 - Train Loss = 0.3945581716299057
Epoch: 21, Batch Index: 4240 - Train Loss = 0.39445908427238463
Epoch: 21, Batch Index: 4260 - Train Loss = 0.3962094861268997
Epoch: 21, Batch Index: 4280 - Train Loss = 0.3951468074321747
Epoch: 21, Batch Index: 4300 - Train Loss = 0.39595333993434906
Epoch: 21, Batch Index: 4320 - Train Loss = 0.395151863694191
Epoch: 21, Batch Index: 4340 - Train Loss = 0.39526971757411955
Epoch: 21, Batch Index: 4360 - Train Loss = 0.3947946810722351
Epoch: 21, Batch Index: 4380 - Train Loss = 0.39302993059158325
Starting Epoch Index 22
Evaluating train set
Epoch: 22, Batch Index: 4400- Eval train - q_loss = 0.39206 , q_risk_0.1 = 0.21964 , q_risk_0.5 = 0.53048 , q_risk_0.9 = 0.23287
Evaluating validation set
Epoch: 22, Batch Index: 4400- Eval validation - q_loss = 0.36915 , q_risk_0.1 = 0.18938 , q_risk_0.5 = 0.50222 , q_risk_0.9 = 0.22966
Evaluating test set
Epoch: 22, Batch Index: 4400- Eval test - q_loss = 0.40324 , q_risk_0.1 = 0.22303 , q_risk_0.5 = 0.55001 , q_risk_0.9 = 0.24596
Epoch: 22, Batch Index: 4400 - Train Loss = 0.39459427058696744
Epoch: 22, Batch Index: 4420 - Train Loss = 0.39634298622608183
Epoch: 22, Batch Index: 4440 - Train Loss = 0.39520590722560883
Epoch: 22, Batch Index: 4460 - Train Loss = 0.3947066628932953
Epoch: 22, Batch Index: 4480 - Train Loss = 0.3930360192060471
Epoch: 22, Batch Index: 4500 - Train Loss = 0.39248515069484713
Epoch: 22, Batch Index: 4520 - Train Loss = 0.39127005636692047
Epoch: 22, Batch Index: 4540 - Train Loss = 0.39145886957645415
Epoch: 22, Batch Index: 4560 - Train Loss = 0.3920900499820709
Epoch: 22, Batch Index: 4580 - Train Loss = 0.3926798003911972
Starting Epoch Index 23
Evaluating train set
Epoch: 23, Batch Index: 4600- Eval train - q_loss = 0.39155 , q_risk_0.1 = 0.21827 , q_risk_0.5 = 0.52890 , q_risk_0.9 = 0.23286
Evaluating validation set
Epoch: 23, Batch Index: 4600- Eval validation - q_loss = 0.36815 , q_risk_0.1 = 0.18785 , q_risk_0.5 = 0.50171 , q_risk_0.9 = 0.23012
Evaluating test set
Epoch: 23, Batch Index: 4600- Eval test - q_loss = 0.40267 , q_risk_0.1 = 0.22320 , q_risk_0.5 = 0.55040 , q_risk_0.9 = 0.24688
Epoch: 23, Batch Index: 4600 - Train Loss = 0.39227204382419584
Epoch: 23, Batch Index: 4620 - Train Loss = 0.3929760956764221
Epoch: 23, Batch Index: 4640 - Train Loss = 0.3935382664203644
Epoch: 23, Batch Index: 4660 - Train Loss = 0.39361579656600953
Epoch: 23, Batch Index: 4680 - Train Loss = 0.39424279212951663
Epoch: 23, Batch Index: 4700 - Train Loss = 0.3931339681148529
Epoch: 23, Batch Index: 4720 - Train Loss = 0.3931455683708191
Epoch: 23, Batch Index: 4740 - Train Loss = 0.3931664407253265
Epoch: 23, Batch Index: 4760 - Train Loss = 0.3928477704524994
Epoch: 23, Batch Index: 4780 - Train Loss = 0.39345218300819396
Starting Epoch Index 24
Evaluating train set
Epoch: 24, Batch Index: 4800- Eval train - q_loss = 0.39214 , q_risk_0.1 = 0.21862 , q_risk_0.5 = 0.52869 , q_risk_0.9 = 0.23219
Evaluating validation set
Epoch: 24, Batch Index: 4800- Eval validation - q_loss = 0.36913 , q_risk_0.1 = 0.18925 , q_risk_0.5 = 0.50214 , q_risk_0.9 = 0.23028
Evaluating test set
Epoch: 24, Batch Index: 4800- Eval test - q_loss = 0.40326 , q_risk_0.1 = 0.22288 , q_risk_0.5 = 0.54883 , q_risk_0.9 = 0.24482
Epoch: 24, Batch Index: 4800 - Train Loss = 0.3950225329399109
Epoch: 24, Batch Index: 4820 - Train Loss = 0.39488036930561066
Epoch: 24, Batch Index: 4840 - Train Loss = 0.39516678869724275
Epoch: 24, Batch Index: 4860 - Train Loss = 0.3929958659410477
Epoch: 24, Batch Index: 4880 - Train Loss = 0.3924259179830551
Epoch: 24, Batch Index: 4900 - Train Loss = 0.39117429077625276
Epoch: 24, Batch Index: 4920 - Train Loss = 0.3929921966791153
Epoch: 24, Batch Index: 4940 - Train Loss = 0.39216280400753023
Epoch: 24, Batch Index: 4960 - Train Loss = 0.3927179759740829
Epoch: 24, Batch Index: 4980 - Train Loss = 0.3926617836952209
Starting Epoch Index 25
Evaluating train set
Epoch: 25, Batch Index: 5000- Eval train - q_loss = 0.39056 , q_risk_0.1 = 0.21834 , q_risk_0.5 = 0.52877 , q_risk_0.9 = 0.23179
Evaluating validation set
Epoch: 25, Batch Index: 5000- Eval validation - q_loss = 0.36815 , q_risk_0.1 = 0.18911 , q_risk_0.5 = 0.50049 , q_risk_0.9 = 0.22966
Evaluating test set
Epoch: 25, Batch Index: 5000- Eval test - q_loss = 0.40302 , q_risk_0.1 = 0.22352 , q_risk_0.5 = 0.54929 , q_risk_0.9 = 0.24501
Epoch: 25, Batch Index: 5000 - Train Loss = 0.39332170248031617
Epoch: 25, Batch Index: 5020 - Train Loss = 0.39254851162433624
Epoch: 25, Batch Index: 5040 - Train Loss = 0.39322559654712674
Epoch: 25, Batch Index: 5060 - Train Loss = 0.3938196575641632
Epoch: 25, Batch Index: 5080 - Train Loss = 0.3937125062942505
Epoch: 25, Batch Index: 5100 - Train Loss = 0.3928701663017273
Epoch: 25, Batch Index: 5120 - Train Loss = 0.39181126058101656
Epoch: 25, Batch Index: 5140 - Train Loss = 0.39321758210659025
Epoch: 25, Batch Index: 5160 - Train Loss = 0.3933630484342575
Epoch: 25, Batch Index: 5180 - Train Loss = 0.39215188562870024
Starting Epoch Index 26
Evaluating train set
Epoch: 26, Batch Index: 5200- Eval train - q_loss = 0.39137 , q_risk_0.1 = 0.21849 , q_risk_0.5 = 0.52926 , q_risk_0.9 = 0.23423
Evaluating validation set
Epoch: 26, Batch Index: 5200- Eval validation - q_loss = 0.36885 , q_risk_0.1 = 0.18826 , q_risk_0.5 = 0.50002 , q_risk_0.9 = 0.23157
Evaluating test set
Epoch: 26, Batch Index: 5200- Eval test - q_loss = 0.40323 , q_risk_0.1 = 0.22326 , q_risk_0.5 = 0.54925 , q_risk_0.9 = 0.24791
Epoch: 26, Batch Index: 5200 - Train Loss = 0.39051229596138
Epoch: 26, Batch Index: 5220 - Train Loss = 0.3913393777608871
Epoch: 26, Batch Index: 5240 - Train Loss = 0.39241084396839143
Epoch: 26, Batch Index: 5260 - Train Loss = 0.39269323766231534
Epoch: 26, Batch Index: 5280 - Train Loss = 0.39189968168735506
Epoch: 26, Batch Index: 5300 - Train Loss = 0.3930205118656158
Epoch: 26, Batch Index: 5320 - Train Loss = 0.3920383912324905
Epoch: 26, Batch Index: 5340 - Train Loss = 0.3897238308191299
Epoch: 26, Batch Index: 5360 - Train Loss = 0.38962125360965727
Epoch: 26, Batch Index: 5380 - Train Loss = 0.3904654240608215
Starting Epoch Index 27
Evaluating train set
Epoch: 27, Batch Index: 5400- Eval train - q_loss = 0.39039 , q_risk_0.1 = 0.21783 , q_risk_0.5 = 0.52829 , q_risk_0.9 = 0.23140
Evaluating validation set
Epoch: 27, Batch Index: 5400- Eval validation - q_loss = 0.36754 , q_risk_0.1 = 0.18775 , q_risk_0.5 = 0.50060 , q_risk_0.9 = 0.22953
Evaluating test set
Epoch: 27, Batch Index: 5400- Eval test - q_loss = 0.40190 , q_risk_0.1 = 0.22277 , q_risk_0.5 = 0.54872 , q_risk_0.9 = 0.24421
Epoch: 27, Batch Index: 5400 - Train Loss = 0.39024166464805604
Epoch: 27, Batch Index: 5420 - Train Loss = 0.39007842659950254
Epoch: 27, Batch Index: 5440 - Train Loss = 0.39056179583072664
Epoch: 27, Batch Index: 5460 - Train Loss = 0.39247548520565034
Epoch: 27, Batch Index: 5480 - Train Loss = 0.3926448619365692
Epoch: 27, Batch Index: 5500 - Train Loss = 0.3919538342952728
Epoch: 27, Batch Index: 5520 - Train Loss = 0.39180775225162506
Epoch: 27, Batch Index: 5540 - Train Loss = 0.3924874305725098
Epoch: 27, Batch Index: 5560 - Train Loss = 0.39209897339344024
Epoch: 27, Batch Index: 5580 - Train Loss = 0.3909041774272919
Starting Epoch Index 28
Evaluating train set
Epoch: 28, Batch Index: 5600- Eval train - q_loss = 0.39188 , q_risk_0.1 = 0.22061 , q_risk_0.5 = 0.52749 , q_risk_0.9 = 0.23275
Evaluating validation set
Epoch: 28, Batch Index: 5600- Eval validation - q_loss = 0.36908 , q_risk_0.1 = 0.19048 , q_risk_0.5 = 0.50131 , q_risk_0.9 = 0.23113
Evaluating test set
Epoch: 28, Batch Index: 5600- Eval test - q_loss = 0.40335 , q_risk_0.1 = 0.22572 , q_risk_0.5 = 0.54895 , q_risk_0.9 = 0.24535
Epoch: 28, Batch Index: 5600 - Train Loss = 0.3908487778902054
Epoch: 28, Batch Index: 5620 - Train Loss = 0.3896499782800674
Epoch: 28, Batch Index: 5640 - Train Loss = 0.38965670883655545
Epoch: 28, Batch Index: 5660 - Train Loss = 0.38986784875392916
Epoch: 28, Batch Index: 5680 - Train Loss = 0.3901781874895096
Epoch: 28, Batch Index: 5700 - Train Loss = 0.39123699903488157
Epoch: 28, Batch Index: 5720 - Train Loss = 0.39091030061244963
Epoch: 28, Batch Index: 5740 - Train Loss = 0.3918015950918198
Epoch: 28, Batch Index: 5760 - Train Loss = 0.39294355988502505
Epoch: 28, Batch Index: 5780 - Train Loss = 0.39244604110717773
Starting Epoch Index 29
Evaluating train set
Epoch: 29, Batch Index: 5800- Eval train - q_loss = 0.39404 , q_risk_0.1 = 0.21937 , q_risk_0.5 = 0.53255 , q_risk_0.9 = 0.23278
Evaluating validation set
Epoch: 29, Batch Index: 5800- Eval validation - q_loss = 0.37405 , q_risk_0.1 = 0.19178 , q_risk_0.5 = 0.50942 , q_risk_0.9 = 0.23223
Evaluating test set
Epoch: 29, Batch Index: 5800- Eval test - q_loss = 0.40477 , q_risk_0.1 = 0.22429 , q_risk_0.5 = 0.55196 , q_risk_0.9 = 0.24415
Epoch: 29, Batch Index: 5800 - Train Loss = 0.39206059992313386
Epoch: 29, Batch Index: 5820 - Train Loss = 0.39203069686889647
Epoch: 29, Batch Index: 5840 - Train Loss = 0.3919054883718491
Epoch: 29, Batch Index: 5860 - Train Loss = 0.39164629876613616
Epoch: 29, Batch Index: 5880 - Train Loss = 0.3922423160076141
Epoch: 29, Batch Index: 5900 - Train Loss = 0.3921043461561203
Epoch: 29, Batch Index: 5920 - Train Loss = 0.393098851442337
Epoch: 29, Batch Index: 5940 - Train Loss = 0.39212001621723175
Epoch: 29, Batch Index: 5960 - Train Loss = 0.3920519644021988
Epoch: 29, Batch Index: 5980 - Train Loss = 0.3909828722476959
Starting Epoch Index 30
Evaluating train set
Epoch: 30, Batch Index: 6000- Eval train - q_loss = 0.38974 , q_risk_0.1 = 0.21782 , q_risk_0.5 = 0.52855 , q_risk_0.9 = 0.23203
Evaluating validation set
Epoch: 30, Batch Index: 6000- Eval validation - q_loss = 0.36657 , q_risk_0.1 = 0.18682 , q_risk_0.5 = 0.49866 , q_risk_0.9 = 0.22842
Evaluating test set
Epoch: 30, Batch Index: 6000- Eval test - q_loss = 0.40124 , q_risk_0.1 = 0.22212 , q_risk_0.5 = 0.54679 , q_risk_0.9 = 0.24366
Epoch: 30, Batch Index: 6000 - Train Loss = 0.39088509261608123
Epoch: 30, Batch Index: 6020 - Train Loss = 0.39050381898880004
Epoch: 30, Batch Index: 6040 - Train Loss = 0.39037124276161195
Epoch: 30, Batch Index: 6060 - Train Loss = 0.3918013191223145
Epoch: 30, Batch Index: 6080 - Train Loss = 0.3919287568330765
Epoch: 30, Batch Index: 6100 - Train Loss = 0.39076375365257265
Epoch: 30, Batch Index: 6120 - Train Loss = 0.39015022993087767
Epoch: 30, Batch Index: 6140 - Train Loss = 0.39081541419029237
Epoch: 30, Batch Index: 6160 - Train Loss = 0.39198262214660645
Epoch: 30, Batch Index: 6180 - Train Loss = 0.3911320555210114
Starting Epoch Index 31
Evaluating train set
Epoch: 31, Batch Index: 6200- Eval train - q_loss = 0.39024 , q_risk_0.1 = 0.21828 , q_risk_0.5 = 0.52971 , q_risk_0.9 = 0.23302
Evaluating validation set
Epoch: 31, Batch Index: 6200- Eval validation - q_loss = 0.36715 , q_risk_0.1 = 0.18745 , q_risk_0.5 = 0.50057 , q_risk_0.9 = 0.22934
Evaluating test set
Epoch: 31, Batch Index: 6200- Eval test - q_loss = 0.40257 , q_risk_0.1 = 0.22277 , q_risk_0.5 = 0.55001 , q_risk_0.9 = 0.24601
Epoch: 31, Batch Index: 6200 - Train Loss = 0.3907492882013321
Epoch: 31, Batch Index: 6220 - Train Loss = 0.3906256502866745
Epoch: 31, Batch Index: 6240 - Train Loss = 0.39096154272556305
Epoch: 31, Batch Index: 6260 - Train Loss = 0.38976613104343416
Epoch: 31, Batch Index: 6280 - Train Loss = 0.38922475814819335
Epoch: 31, Batch Index: 6300 - Train Loss = 0.3899465698003769
Epoch: 31, Batch Index: 6320 - Train Loss = 0.38967978656291963
Epoch: 31, Batch Index: 6340 - Train Loss = 0.38768147528171537
Epoch: 31, Batch Index: 6360 - Train Loss = 0.3869838571548462
Epoch: 31, Batch Index: 6380 - Train Loss = 0.388415789604187
Starting Epoch Index 32
Evaluating train set
Epoch: 32, Batch Index: 6400- Eval train - q_loss = 0.39096 , q_risk_0.1 = 0.21945 , q_risk_0.5 = 0.52666 , q_risk_0.9 = 0.23163
Evaluating validation set
Epoch: 32, Batch Index: 6400- Eval validation - q_loss = 0.36839 , q_risk_0.1 = 0.18939 , q_risk_0.5 = 0.50079 , q_risk_0.9 = 0.22963
Evaluating test set
Epoch: 32, Batch Index: 6400- Eval test - q_loss = 0.40248 , q_risk_0.1 = 0.22379 , q_risk_0.5 = 0.54669 , q_risk_0.9 = 0.24449
Epoch: 32, Batch Index: 6400 - Train Loss = 0.3901190936565399
Epoch: 32, Batch Index: 6420 - Train Loss = 0.3902225261926651
Epoch: 32, Batch Index: 6440 - Train Loss = 0.38986050844192505
Epoch: 32, Batch Index: 6460 - Train Loss = 0.390974235534668
Epoch: 32, Batch Index: 6480 - Train Loss = 0.39193484365940096
Epoch: 32, Batch Index: 6500 - Train Loss = 0.39073346972465517
Epoch: 32, Batch Index: 6520 - Train Loss = 0.39032455027103424
Epoch: 32, Batch Index: 6540 - Train Loss = 0.3908982783555984
Epoch: 32, Batch Index: 6560 - Train Loss = 0.3922088122367859
Epoch: 32, Batch Index: 6580 - Train Loss = 0.3926752859354019
Starting Epoch Index 33
Evaluating train set
Epoch: 33, Batch Index: 6600- Eval train - q_loss = 0.38956 , q_risk_0.1 = 0.21672 , q_risk_0.5 = 0.52588 , q_risk_0.9 = 0.23119
Evaluating validation set
Epoch: 33, Batch Index: 6600- Eval validation - q_loss = 0.36684 , q_risk_0.1 = 0.18713 , q_risk_0.5 = 0.49937 , q_risk_0.9 = 0.22901
Evaluating test set
Epoch: 33, Batch Index: 6600- Eval test - q_loss = 0.40247 , q_risk_0.1 = 0.22182 , q_risk_0.5 = 0.54800 , q_risk_0.9 = 0.24521
Epoch: 33, Batch Index: 6600 - Train Loss = 0.3935240590572357
Epoch: 33, Batch Index: 6620 - Train Loss = 0.3925152826309204
Epoch: 33, Batch Index: 6640 - Train Loss = 0.3917000460624695
Epoch: 33, Batch Index: 6660 - Train Loss = 0.39040002346038816
Epoch: 33, Batch Index: 6680 - Train Loss = 0.3905193430185318
Epoch: 33, Batch Index: 6700 - Train Loss = 0.39004546344280244
Epoch: 33, Batch Index: 6720 - Train Loss = 0.39133926808834074
Epoch: 33, Batch Index: 6740 - Train Loss = 0.3922427821159363
Epoch: 33, Batch Index: 6760 - Train Loss = 0.39129244804382324
Epoch: 33, Batch Index: 6780 - Train Loss = 0.39056913316249847
Starting Epoch Index 34
Evaluating train set
Epoch: 34, Batch Index: 6800- Eval train - q_loss = 0.38977 , q_risk_0.1 = 0.21672 , q_risk_0.5 = 0.52758 , q_risk_0.9 = 0.23028
Evaluating validation set
Epoch: 34, Batch Index: 6800- Eval validation - q_loss = 0.36813 , q_risk_0.1 = 0.18670 , q_risk_0.5 = 0.50337 , q_risk_0.9 = 0.22875
Evaluating test set
Epoch: 34, Batch Index: 6800- Eval test - q_loss = 0.40385 , q_risk_0.1 = 0.22308 , q_risk_0.5 = 0.55283 , q_risk_0.9 = 0.24623
Epoch: 34, Batch Index: 6800 - Train Loss = 0.39117752134799955
Epoch: 34, Batch Index: 6820 - Train Loss = 0.39211222290992737
Epoch: 34, Batch Index: 6840 - Train Loss = 0.3920974570512772
Epoch: 34, Batch Index: 6860 - Train Loss = 0.39139396011829375
Epoch: 34, Batch Index: 6880 - Train Loss = 0.3928719937801361
Epoch: 34, Batch Index: 6900 - Train Loss = 0.39347449481487273
Epoch: 34, Batch Index: 6920 - Train Loss = 0.394243283867836
Epoch: 34, Batch Index: 6940 - Train Loss = 0.3939601480960846
Epoch: 34, Batch Index: 6960 - Train Loss = 0.39319044470787046
Epoch: 34, Batch Index: 6980 - Train Loss = 0.3914372318983078
Starting Epoch Index 35
Evaluating train set
Epoch: 35, Batch Index: 7000- Eval train - q_loss = 0.39211 , q_risk_0.1 = 0.21793 , q_risk_0.5 = 0.53193 , q_risk_0.9 = 0.23138
Evaluating validation set
Epoch: 35, Batch Index: 7000- Eval validation - q_loss = 0.36915 , q_risk_0.1 = 0.18791 , q_risk_0.5 = 0.50418 , q_risk_0.9 = 0.23011
Evaluating test set
Epoch: 35, Batch Index: 7000- Eval test - q_loss = 0.40479 , q_risk_0.1 = 0.22277 , q_risk_0.5 = 0.55335 , q_risk_0.9 = 0.24528
Performing early stopping...!
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Explore-Model-Outputs">
<h1>Explore Model Outputs<a class="headerlink" href="#Explore-Model-Outputs" title="Permalink to this headline">¶</a></h1>
<p>After training the model, we can use it and its outputs for a better understanding of its performance, and for trying to explain its estimations. That is what will be demonstrated in this tutorial, using the module <code class="docutils literal notranslate"><span class="pre">tft_torch.tft_vis</span></code>. We will rely on the dataset we produced on the dataset creation tutorial and on the model we trained in the model training tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">tft_torch.visualize</span> <span class="k">as</span> <span class="nn">tft_vis</span>
</pre></div>
</div>
</div>
<div class="section" id="Apply-the-model">
<h2>Apply the model<a class="headerlink" href="#Apply-the-model" title="Permalink to this headline">¶</a></h2>
<p>For collecting the outputs of the model, we’ll first run inference on the validation subset. Here we use the serial data loader assigned above:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># switch to evaluation mode</span>

<span class="n">output_aggregator</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="c1"># will be used for aggregating the outputs across batches</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># go over the batches of the serial data loader</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_serial_loader</span><span class="p">):</span>
        <span class="c1"># process each batch</span>
        <span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># accumulate outputs, as well as labels</span>
        <span class="k">for</span> <span class="n">output_key</span><span class="p">,</span><span class="n">output_tensor</span> <span class="ow">in</span> <span class="n">batch_outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">output_aggregator</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">output_key</span><span class="p">,[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">output_aggregator</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 30/30 [00:10&lt;00:00,  2.82it/s]
</pre></div></div>
</div>
<p>and then stack the outpus from all the batches:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">validation_outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">output_aggregator</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="n">validation_outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">output_aggregator</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s say the subset we’re working with includes <span class="math notranslate nohighlight">\(N\)</span> observations, and each observation consists of:</p>
<ul class="simple">
<li><p>a historical time-series that includes <span class="math notranslate nohighlight">\(m_{historical}\)</span> temporal variables, spanning <span class="math notranslate nohighlight">\(T_{past}\)</span> past time-steps.</p></li>
<li><p>a <em>futuristic</em> time-series including <span class="math notranslate nohighlight">\(m_{future}\)</span> temporal variables, spanning <span class="math notranslate nohighlight">\(T_{fut}\)</span> futuristic time-steps.</p></li>
<li><p>a set of <span class="math notranslate nohighlight">\(m_{static}\)</span> static variables.</p></li>
</ul>
<p>In addition, let’s assume that the model is configured to estimate <span class="math notranslate nohighlight">\(d_q\)</span> different quantiles.</p>
<p>In such case the outputs of the model will be as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predicted_quantiles</span></code> - the model quantile estimates for each temporal future step, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times d_q]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">static_weights</span></code> - the selection weights associated with the static variables for each observation, shaped as <span class="math notranslate nohighlight">\([N \times m_{static}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">historical_selection_weights</span></code> - the selection weights associated with the historical temporal variables, for each observation, and past time-step, shaped as <span class="math notranslate nohighlight">\([N \times T_{past} \times m_{historical}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">future_selection_weights</span></code> - the selection weights associated with the future temporal variables, for each observation, and future time-step, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times m_{future}]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">attention_scores</span></code> - the attention score each future time-step associates which each other time-step, for each observation, shaped as <span class="math notranslate nohighlight">\([N \times T_{fut} \times (T_{past} + T_{fut})]\)</span>.</p></li>
</ul>
<p>Some of the illustrations below will refer to a single observation (sample-level), and some will perform aggregation of the outputs for the entire subset data. For that matter, we’ll arbitrarily set an index indicating the sample/record that will be used for the demonstration of the sample-level illustrations:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">chosen_idx</span> <span class="o">=</span> <span class="mi">42421</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Target-Signal-Trajectory">
<h2>Target Signal Trajectory<a class="headerlink" href="#Target-Signal-Trajectory" title="Permalink to this headline">¶</a></h2>
<p>On this section we’ll extract the historical sequence associated with the target variable, for the specific observation chosen, together with the futuristic label (the future target), and the predicted quantiles output by the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># the name of the target signal</span>
<span class="n">target_signal</span> <span class="o">=</span> <span class="s1">&#39;log_sales&#39;</span>
<span class="c1"># its relative index among the set of historical numeric input variables</span>
<span class="n">target_var_index</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">target_signal</span><span class="p">)</span>
<span class="c1"># the quantiles estimated by the trained model</span>
<span class="n">model_quantiles</span> <span class="o">=</span> <span class="n">configuration</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">][</span><span class="s1">&#39;output_quantiles&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>The trajectory can be viewed in two different scales: Our first view will refer to the normalized scale. Recall that before feeding the data to the model, all of our input variables were scaled or encoded. because the target signal was scaled as well, the outputs of the model are also designated to estimate the target signal according to this “<em>new</em>” normalized scale.</p>
<p>In the follwing chart we can see: - on the left: the historical values of the target variable. - dashed line separating past and future. - on the right: (solid) future target variable - what the model aims to predict - on the right: (dashed) dashed lines associated with the predicted quantiles (see legend) - on the right: a colored sleeve between and the lower and upper quantiles; can be seen as the uncertainty sleeve for each horizon.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_target_trajectory</span><span class="p">(</span><span class="n">signal_history</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span><span class="n">target_var_index</span><span class="p">],</span>
                                  <span class="n">signal_future</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>
                                  <span class="n">model_preds</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">],</span>
                                  <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                  <span class="n">model_quantiles</span><span class="o">=</span><span class="n">model_quantiles</span><span class="p">,</span>
                                  <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_70_0.png" src="../_images/tutorials_prevTrainingExample_70_0.png" />
</div>
</div>
<p>However, in some cases we would like to observe the actual scale of the target variable. For that matter, the method we’re using, <code class="docutils literal notranslate"><span class="pre">tft_vis.display_target_trajectory()</span></code> optionally accepts also the input argument <code class="docutils literal notranslate"><span class="pre">transformation</span></code> , which can be used for scaling back the target variable to its original scale.</p>
<p>In our use case, the target variable went through a log-transform (<span class="math notranslate nohighlight">\(log_{10}(1+x)\)</span>), and then scaled using the scaler we saved along with the data. We use this to formulate the inverse scaling, and <em>send</em> this transformation to the visualization utility.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">scale_back</span><span class="p">(</span><span class="n">scaler_obj</span><span class="p">,</span><span class="n">signal</span><span class="p">):</span>
    <span class="n">inv_trans</span> <span class="o">=</span> <span class="n">scaler_obj</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">signal</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">inv_trans</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">transform_back</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">scale_back</span><span class="p">,</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;scalers&#39;</span><span class="p">][</span><span class="s1">&#39;numeric&#39;</span><span class="p">][</span><span class="n">target_signal</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_target_trajectory</span><span class="p">(</span><span class="n">signal_history</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;data_sets&#39;</span><span class="p">][</span><span class="s1">&#39;validation&#39;</span><span class="p">][</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span><span class="n">target_var_index</span><span class="p">],</span>
                                  <span class="n">signal_future</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span>
                                  <span class="n">model_preds</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;predicted_quantiles&#39;</span><span class="p">],</span>
                                  <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                  <span class="n">model_quantiles</span><span class="o">=</span><span class="n">model_quantiles</span><span class="p">,</span>
                                  <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span>
                                  <span class="n">transformation</span><span class="o">=</span><span class="n">transform_back</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_73_0.png" src="../_images/tutorials_prevTrainingExample_73_0.png" />
</div>
</div>
<div class="section" id="Selection-Weights">
<h3>Selection Weights<a class="headerlink" href="#Selection-Weights" title="Permalink to this headline">¶</a></h3>
<p>The temporal fusion transformer model has an interntal mechanism for variable selection. Each input channel has a separate dedicated mechanism - historical temporal data, static descriptors data, known future inputs data. In the following section we’ll describe them visually.</p>
<p>Although the input to the model required us to split between the categorical variables and the numeric variables for each input channel, after the inputs are transformed upon feeding them to the model, the entire set of variables composing a single input channel (historical_ts / future_ts / static) are treated as one block, and the variable selection mechanism acts on them without any distinction.</p>
<p><strong>Note</strong>: in the suggested implementation, the numeric inputs are stacked first, before combining the categorical inputs (on each input channel separately). Hence, we conclude the complete set of input variables for each input channel as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">static_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;static_feats_categorical&#39;</span><span class="p">]</span>
<span class="n">historical_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;historical_ts_categorical&#39;</span><span class="p">]</span>
<span class="n">future_feats</span> <span class="o">=</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_numeric&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_map</span><span class="p">[</span><span class="s1">&#39;future_ts_categorical&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>The description of selection weights can be done either on a data subset level, or on a sample-level. For performing data-set level description, we’ll have to perform some-kind of reduction/aggregation. Hence, we use a configurable list of precentiles, for describing the distribution of selection weights for each variable on each input channel:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># the precentiles to compute for describing the distribution of the weights</span>
<span class="n">weights_prctile</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">90</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>On the following we use the functionality implemented under <code class="docutils literal notranslate"><span class="pre">tft_torch.visualize</span></code>, for performing the aggregation and ordering of the attributes, for each input channel separately. For that matter, we supply a mapping specifying the name of output key associated which each set of attributes:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Static Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;static_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">static_feats</span><span class="p">},</span>
    <span class="s1">&#39;Historical Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;historical_selection_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">historical_feats</span><span class="p">},</span>
    <span class="s1">&#39;Future Weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;arr_key&#39;</span><span class="p">:</span> <span class="s1">&#39;future_selection_weights&#39;</span><span class="p">,</span> <span class="s1">&#39;feat_names&#39;</span><span class="p">:</span><span class="n">future_feats</span><span class="p">},</span>
<span class="p">}</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_selection_weights_stats</span><span class="p">(</span><span class="n">outputs_dict</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">,</span>
                                       <span class="n">prctiles</span><span class="o">=</span><span class="n">weights_prctile</span><span class="p">,</span>
                                       <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                                       <span class="n">sort_by</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Static Weights
=========
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_9d812_row0_col0, #T_9d812_row0_col1, #T_9d812_row0_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_9d812_row1_col0 {
  background-color: #65cb5e;
  color: #000000;
}
#T_9d812_row1_col1 {
  background-color: #69cd5b;
  color: #000000;
}
#T_9d812_row1_col2 {
  background-color: #84d44b;
  color: #000000;
}
#T_9d812_row2_col0 {
  background-color: #228d8d;
  color: #f1f1f1;
}
#T_9d812_row2_col1 {
  background-color: #22a785;
  color: #f1f1f1;
}
#T_9d812_row2_col2 {
  background-color: #58c765;
  color: #000000;
}
#T_9d812_row3_col0, #T_9d812_row6_col2 {
  background-color: #2c738e;
  color: #f1f1f1;
}
#T_9d812_row3_col1 {
  background-color: #2a788e;
  color: #f1f1f1;
}
#T_9d812_row3_col2 {
  background-color: #277f8e;
  color: #f1f1f1;
}
#T_9d812_row4_col0 {
  background-color: #2e6d8e;
  color: #f1f1f1;
}
#T_9d812_row4_col1 {
  background-color: #2b748e;
  color: #f1f1f1;
}
#T_9d812_row4_col2 {
  background-color: #25848e;
  color: #f1f1f1;
}
#T_9d812_row5_col0 {
  background-color: #375b8d;
  color: #f1f1f1;
}
#T_9d812_row5_col1 {
  background-color: #2e6e8e;
  color: #f1f1f1;
}
#T_9d812_row5_col2 {
  background-color: #23898e;
  color: #f1f1f1;
}
#T_9d812_row6_col0 {
  background-color: #3e4989;
  color: #f1f1f1;
}
#T_9d812_row6_col1 {
  background-color: #38598c;
  color: #f1f1f1;
}
#T_9d812_row7_col0 {
  background-color: #453781;
  color: #f1f1f1;
}
#T_9d812_row7_col1 {
  background-color: #404588;
  color: #f1f1f1;
}
#T_9d812_row7_col2 {
  background-color: #34608d;
  color: #f1f1f1;
}
#T_9d812_row8_col0, #T_9d812_row8_col1, #T_9d812_row8_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
</style>
<table id="T_9d812_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_9d812_level0_row0" class="row_heading level0 row0" >item_class</th>
      <td id="T_9d812_row0_col0" class="data row0 col0" >0.150147</td>
      <td id="T_9d812_row0_col1" class="data row0 col1" >0.224345</td>
      <td id="T_9d812_row0_col2" class="data row0 col2" >0.303914</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row1" class="row_heading level0 row1" >item_nbr</th>
      <td id="T_9d812_row1_col0" class="data row1 col0" >0.116679</td>
      <td id="T_9d812_row1_col1" class="data row1 col1" >0.175261</td>
      <td id="T_9d812_row1_col2" class="data row1 col2" >0.250054</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row2" class="row_heading level0 row2" >store_nbr</th>
      <td id="T_9d812_row2_col0" class="data row2 col0" >0.077795</td>
      <td id="T_9d812_row2_col1" class="data row2 col1" >0.137444</td>
      <td id="T_9d812_row2_col2" class="data row2 col2" >0.228214</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row3" class="row_heading level0 row3" >store_type</th>
      <td id="T_9d812_row3_col0" class="data row3 col0" >0.062463</td>
      <td id="T_9d812_row3_col1" class="data row3 col1" >0.096023</td>
      <td id="T_9d812_row3_col2" class="data row3 col2" >0.137529</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row4" class="row_heading level0 row4" >city</th>
      <td id="T_9d812_row4_col0" class="data row4 col0" >0.058623</td>
      <td id="T_9d812_row4_col1" class="data row4 col1" >0.092370</td>
      <td id="T_9d812_row4_col2" class="data row4 col2" >0.144627</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row5" class="row_heading level0 row5" >item_family</th>
      <td id="T_9d812_row5_col0" class="data row5 col0" >0.048706</td>
      <td id="T_9d812_row5_col1" class="data row5 col1" >0.086409</td>
      <td id="T_9d812_row5_col2" class="data row5 col2" >0.149678</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row6" class="row_heading level0 row6" >store_cluster</th>
      <td id="T_9d812_row6_col0" class="data row6 col0" >0.040277</td>
      <td id="T_9d812_row6_col1" class="data row6 col1" >0.069490</td>
      <td id="T_9d812_row6_col2" class="data row6 col2" >0.124298</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row7" class="row_heading level0 row7" >perishable</th>
      <td id="T_9d812_row7_col0" class="data row7 col0" >0.031059</td>
      <td id="T_9d812_row7_col1" class="data row7 col1" >0.053998</td>
      <td id="T_9d812_row7_col2" class="data row7 col2" >0.101199</td>
    </tr>
    <tr>
      <th id="T_9d812_level0_row8" class="row_heading level0 row8" >state</th>
      <td id="T_9d812_row8_col0" class="data row8 col0" >0.008889</td>
      <td id="T_9d812_row8_col1" class="data row8 col1" >0.010247</td>
      <td id="T_9d812_row8_col2" class="data row8 col2" >0.013222</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Historical Weights
=========
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_e62bc_row0_col0, #T_e62bc_row0_col1, #T_e62bc_row0_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_e62bc_row1_col0 {
  background-color: #228c8d;
  color: #f1f1f1;
}
#T_e62bc_row1_col1 {
  background-color: #1f9a8a;
  color: #f1f1f1;
}
#T_e62bc_row1_col2 {
  background-color: #1e9d89;
  color: #f1f1f1;
}
#T_e62bc_row2_col0 {
  background-color: #481668;
  color: #f1f1f1;
}
#T_e62bc_row2_col1, #T_e62bc_row3_col2 {
  background-color: #481b6d;
  color: #f1f1f1;
}
#T_e62bc_row2_col2 {
  background-color: #482979;
  color: #f1f1f1;
}
#T_e62bc_row3_col0 {
  background-color: #46085c;
  color: #f1f1f1;
}
#T_e62bc_row3_col1 {
  background-color: #471063;
  color: #f1f1f1;
}
#T_e62bc_row4_col0, #T_e62bc_row4_col1, #T_e62bc_row6_col2 {
  background-color: #46075a;
  color: #f1f1f1;
}
#T_e62bc_row4_col2 {
  background-color: #471164;
  color: #f1f1f1;
}
#T_e62bc_row5_col0, #T_e62bc_row7_col0, #T_e62bc_row10_col0 {
  background-color: #440256;
  color: #f1f1f1;
}
#T_e62bc_row5_col1, #T_e62bc_row6_col0, #T_e62bc_row6_col1, #T_e62bc_row7_col1 {
  background-color: #450457;
  color: #f1f1f1;
}
#T_e62bc_row5_col2 {
  background-color: #460b5e;
  color: #f1f1f1;
}
#T_e62bc_row7_col2 {
  background-color: #450559;
  color: #f1f1f1;
}
#T_e62bc_row8_col0, #T_e62bc_row8_col1, #T_e62bc_row9_col0, #T_e62bc_row9_col1, #T_e62bc_row10_col1, #T_e62bc_row10_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
#T_e62bc_row8_col2 {
  background-color: #470e61;
  color: #f1f1f1;
}
#T_e62bc_row9_col2 {
  background-color: #470d60;
  color: #f1f1f1;
}
</style>
<table id="T_e62bc_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_e62bc_level0_row0" class="row_heading level0 row0" >log_sales</th>
      <td id="T_e62bc_row0_col0" class="data row0 col0" >0.422607</td>
      <td id="T_e62bc_row0_col1" class="data row0 col1" >0.485794</td>
      <td id="T_e62bc_row0_col2" class="data row0 col2" >0.534387</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row1" class="row_heading level0 row1" >day_of_week</th>
      <td id="T_e62bc_row1_col0" class="data row1 col0" >0.209394</td>
      <td id="T_e62bc_row1_col1" class="data row1 col1" >0.270953</td>
      <td id="T_e62bc_row1_col2" class="data row1 col2" >0.304412</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row2" class="row_heading level0 row2" >onpromotion</th>
      <td id="T_e62bc_row2_col0" class="data row2 col0" >0.034833</td>
      <td id="T_e62bc_row2_col1" class="data row2 col1" >0.049608</td>
      <td id="T_e62bc_row2_col2" class="data row2 col2" >0.079693</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row3" class="row_heading level0 row3" >day_of_month</th>
      <td id="T_e62bc_row3_col0" class="data row3 col0" >0.020465</td>
      <td id="T_e62bc_row3_col1" class="data row3 col1" >0.035053</td>
      <td id="T_e62bc_row3_col2" class="data row3 col2" >0.056229</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row4" class="row_heading level0 row4" >open</th>
      <td id="T_e62bc_row4_col0" class="data row4 col0" >0.017500</td>
      <td id="T_e62bc_row4_col1" class="data row4 col1" >0.024302</td>
      <td id="T_e62bc_row4_col2" class="data row4 col2" >0.041939</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row5" class="row_heading level0 row5" >oil_price</th>
      <td id="T_e62bc_row5_col0" class="data row5 col0" >0.013561</td>
      <td id="T_e62bc_row5_col1" class="data row5 col1" >0.021311</td>
      <td id="T_e62bc_row5_col2" class="data row5 col2" >0.034703</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row6" class="row_heading level0 row6" >local_holiday</th>
      <td id="T_e62bc_row6_col0" class="data row6 col0" >0.015344</td>
      <td id="T_e62bc_row6_col1" class="data row6 col1" >0.020328</td>
      <td id="T_e62bc_row6_col2" class="data row6 col2" >0.028917</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row7" class="row_heading level0 row7" >transactions</th>
      <td id="T_e62bc_row7_col0" class="data row7 col0" >0.013129</td>
      <td id="T_e62bc_row7_col1" class="data row7 col1" >0.020139</td>
      <td id="T_e62bc_row7_col2" class="data row7 col2" >0.027684</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row8" class="row_heading level0 row8" >regional_holiday</th>
      <td id="T_e62bc_row8_col0" class="data row8 col0" >0.010872</td>
      <td id="T_e62bc_row8_col1" class="data row8 col1" >0.018223</td>
      <td id="T_e62bc_row8_col2" class="data row8 col2" >0.038747</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row9" class="row_heading level0 row9" >month</th>
      <td id="T_e62bc_row9_col0" class="data row9 col0" >0.011719</td>
      <td id="T_e62bc_row9_col1" class="data row9 col1" >0.017241</td>
      <td id="T_e62bc_row9_col2" class="data row9 col2" >0.036102</td>
    </tr>
    <tr>
      <th id="T_e62bc_level0_row10" class="row_heading level0 row10" >national_holiday</th>
      <td id="T_e62bc_row10_col0" class="data row10 col0" >0.013915</td>
      <td id="T_e62bc_row10_col1" class="data row10 col1" >0.016406</td>
      <td id="T_e62bc_row10_col2" class="data row10 col2" >0.019726</td>
    </tr>
  </tbody>
</table></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Future Weights
=========
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<style type="text/css">
#T_7350a_row0_col0, #T_7350a_row0_col1, #T_7350a_row0_col2 {
  background-color: #fde725;
  color: #000000;
}
#T_7350a_row1_col0 {
  background-color: #2b748e;
  color: #f1f1f1;
}
#T_7350a_row1_col1 {
  background-color: #238a8d;
  color: #f1f1f1;
}
#T_7350a_row1_col2 {
  background-color: #1f9f88;
  color: #f1f1f1;
}
#T_7350a_row2_col0 {
  background-color: #2c718e;
  color: #f1f1f1;
}
#T_7350a_row2_col1 {
  background-color: #297a8e;
  color: #f1f1f1;
}
#T_7350a_row2_col2 {
  background-color: #20928c;
  color: #f1f1f1;
}
#T_7350a_row3_col0 {
  background-color: #3e4c8a;
  color: #f1f1f1;
}
#T_7350a_row3_col1 {
  background-color: #3a538b;
  color: #f1f1f1;
}
#T_7350a_row3_col2 {
  background-color: #375b8d;
  color: #f1f1f1;
}
#T_7350a_row4_col0 {
  background-color: #472f7d;
  color: #f1f1f1;
}
#T_7350a_row4_col1 {
  background-color: #3d4e8a;
  color: #f1f1f1;
}
#T_7350a_row4_col2 {
  background-color: #3a548c;
  color: #f1f1f1;
}
#T_7350a_row5_col0 {
  background-color: #482071;
  color: #f1f1f1;
}
#T_7350a_row5_col1 {
  background-color: #472a7a;
  color: #f1f1f1;
}
#T_7350a_row5_col2 {
  background-color: #443983;
  color: #f1f1f1;
}
#T_7350a_row6_col0 {
  background-color: #470d60;
  color: #f1f1f1;
}
#T_7350a_row6_col1 {
  background-color: #471164;
  color: #f1f1f1;
}
#T_7350a_row6_col2 {
  background-color: #470e61;
  color: #f1f1f1;
}
#T_7350a_row7_col0, #T_7350a_row7_col1, #T_7350a_row7_col2 {
  background-color: #440154;
  color: #f1f1f1;
}
</style>
<table id="T_7350a_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >10</th>
      <th class="col_heading level0 col1" >50</th>
      <th class="col_heading level0 col2" >90</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_7350a_level0_row0" class="row_heading level0 row0" >day_of_week</th>
      <td id="T_7350a_row0_col0" class="data row0 col0" >0.278989</td>
      <td id="T_7350a_row0_col1" class="data row0 col1" >0.354945</td>
      <td id="T_7350a_row0_col2" class="data row0 col2" >0.444539</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row1" class="row_heading level0 row1" >day_of_month</th>
      <td id="T_7350a_row1_col0" class="data row1 col0" >0.111591</td>
      <td id="T_7350a_row1_col1" class="data row1 col1" >0.173309</td>
      <td id="T_7350a_row1_col2" class="data row1 col2" >0.260713</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row2" class="row_heading level0 row2" >onpromotion</th>
      <td id="T_7350a_row2_col0" class="data row2 col0" >0.108272</td>
      <td id="T_7350a_row2_col1" class="data row2 col1" >0.150257</td>
      <td id="T_7350a_row2_col2" class="data row2 col2" >0.238843</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row3" class="row_heading level0 row3" >regional_holiday</th>
      <td id="T_7350a_row3_col0" class="data row3 col0" >0.069319</td>
      <td id="T_7350a_row3_col1" class="data row3 col1" >0.097379</td>
      <td id="T_7350a_row3_col2" class="data row3 col2" >0.145683</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row4" class="row_heading level0 row4" >national_holiday</th>
      <td id="T_7350a_row4_col0" class="data row4 col0" >0.043135</td>
      <td id="T_7350a_row4_col1" class="data row4 col1" >0.090677</td>
      <td id="T_7350a_row4_col2" class="data row4 col2" >0.136553</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row5" class="row_heading level0 row5" >month</th>
      <td id="T_7350a_row5_col0" class="data row5 col0" >0.031223</td>
      <td id="T_7350a_row5_col1" class="data row5 col1" >0.051035</td>
      <td id="T_7350a_row5_col2" class="data row5 col2" >0.097063</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row6" class="row_heading level0 row6" >open</th>
      <td id="T_7350a_row6_col0" class="data row6 col0" >0.015355</td>
      <td id="T_7350a_row6_col1" class="data row6 col1" >0.025633</td>
      <td id="T_7350a_row6_col2" class="data row6 col2" >0.043699</td>
    </tr>
    <tr>
      <th id="T_7350a_level0_row7" class="row_heading level0 row7" >local_holiday</th>
      <td id="T_7350a_row7_col0" class="data row7 col0" >0.006801</td>
      <td id="T_7350a_row7_col1" class="data row7 col1" >0.009700</td>
      <td id="T_7350a_row7_col2" class="data row7 col2" >0.027452</td>
    </tr>
  </tbody>
</table></div>
</div>
<p>The tables above display the specified percentiles of the weights distribution for each feature, on each input channel. The color of each cell is highlighted according to the corresponding value (brighter color implies higher value). In addition, every table is sorted (in descending order) according to configured percentile. Note that for the temporal inputs (historical_ts, future_ts), the time-series of weights gets “flattened”, so that we can aggregate along time-steps and samples likewise.
Generally, the selection weights for the temporal data, are generated for each time-step separately. Here, we look at all the time-steps altogether, but this can be another aspect to examine.</p>
<p>Some interesting findings that are easily seen using these tables:</p>
<ul class="simple">
<li><p>For the static weights, the attributes that seem to have the highest weights (thus considered more important), are the ones associated with the identity of the instance - <em>store_nbr</em> , <em>item_class</em> , <em>item_nbr</em> .</p></li>
<li><p>The most important variable, in terms of selection weight, among the historical features, is the variable we aim at predicting into the future - <em>log_sales</em> - which makes sense, of course.</p></li>
<li><p>Among the known (futuristic) inputs, we see that the knowledge about the next weekdays and the upcoming promotions is of high importance to the model.</p></li>
</ul>
<p>As noted earlier, we can examine the selection weights from the point of view of an invdividual sample. Using the functionality implemented on <code class="docutils literal notranslate"><span class="pre">tft_torch.visualize</span></code> we call <code class="docutils literal notranslate"><span class="pre">display_sample_wise_selection_stats()</span></code> function, each time for another input channel, specying the observation index for which we want to observe the selection weights distribution.</p>
<ul class="simple">
<li><p>For each of the input channel we get an ordered barplot of the selection weights. Note that for the selection weights of the temporal attributes, there’s a step of flattening and averaging. For the barplot we also allow specifying the <code class="docutils literal notranslate"><span class="pre">top_n</span></code> argument, for keeping only the <code class="docutils literal notranslate"><span class="pre">top_n</span></code> ranked attributes on this plot. Note that the selection weights on the barplot, for the static variables (which do not require flattening and aggregation) sum up to 1.0 (unless truncated using <code class="docutils literal notranslate"><span class="pre">top_n</span></code>).</p></li>
<li><p>For the selection weights of the temporal input channel, the same function will also provide some kind of “<em>spectrogram</em>” indicating the distribution of selection weights along time. This visualization can be configured to rank the attributes separately on each time-step, by setting <code class="docutils literal notranslate"><span class="pre">rank_stepwise=True</span></code>.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># static attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;static_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">static_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Static Features&#39;</span><span class="p">)</span>

<span class="c1"># historical temporal attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;historical_selection_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">historical_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Historical Features&#39;</span><span class="p">,</span>
                                           <span class="n">rank_stepwise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># futuristic (known) temporal attributes</span>
<span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_selection_stats</span><span class="p">(</span><span class="n">weights_arr</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;future_selection_weights&#39;</span><span class="p">],</span>
                                           <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                           <span class="n">feature_names</span><span class="o">=</span><span class="n">future_feats</span><span class="p">,</span>
                                           <span class="n">top_n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Future Features&#39;</span><span class="p">,</span>
                                           <span class="n">historical</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                           <span class="n">rank_stepwise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_85_0.png" src="../_images/tutorials_prevTrainingExample_85_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_85_1.png" src="../_images/tutorials_prevTrainingExample_85_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_85_2.png" src="../_images/tutorials_prevTrainingExample_85_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_85_3.png" src="../_images/tutorials_prevTrainingExample_85_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_85_4.png" src="../_images/tutorials_prevTrainingExample_85_4.png" />
</div>
</div>
<p>Looking at the barplots above, we can see that although in some cases the ordering of selection weights observed for the individual sample does go hand-in-hand with the ordering observed in the aggregative form (on the dataset level), this might not always be the case. Having the ability to observe selection weights on a single sample level enables us to investigate specific samples and understand which variables of this specific sample affected the model the most, and led to un/successful
prediction.</p>
<p>Now, to the additional visualization: as explained above, the distribution of selection weights is different for each time-step. The image-like visualization is used to describe this distribution along time; higher selection weights are depicted by a brighter color. When <code class="docutils literal notranslate"><span class="pre">rank_stepwise</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the visualization is using a uniform scale of selection weights along the entire time axis. Therefore, on time-steps where the distribution of selection weights has higher entropy (less
concentrated with a narrow set of few features), the selected input variables seem (according to chart) “less important”. In order to overcome this, one can set <code class="docutils literal notranslate"><span class="pre">rank_stepwise</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, and the chart will display the same information, but the cells will be colored according to the order of the features (or according to their resepctive selection weight, to be precise) on each time step separately.</p>
</div>
<div class="section" id="Attention-Scores">
<h3>Attention Scores<a class="headerlink" href="#Attention-Scores" title="Permalink to this headline">¶</a></h3>
<p>The temporal fusion transformer model has an internal attention mechanism for weighting the information coming from the sequential data (whether it is the historical sequence or the future sequential data). Part of the model outputs, for each observation, are the attention scores of the model. We can use these scores to try and infer which preceding time-steps affected the output of the model the most. Recall that due to masking, each Future horizon can “assign” attention only to steps that came
before. On this part, we examine the scores both globally (for the entire validation set) and individually (on a single-sample level).</p>
<p>As in the case of aggregating the selection weights, for supply a quantitative description of the scores distribution we use percentiles.</p>
</div>
</div>
<div class="section" id="One-step-ahead">
<h2>One step ahead<a class="headerlink" href="#One-step-ahead" title="Permalink to this headline">¶</a></h2>
<p>The attention scores are horizon-specific, i.e. every future horizon maintains a different set of attention scores for the corresponding observable time-steps. First, we’ll examine the attention scores for a one-day horizon (t+1) into the future.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                <span class="n">horizons</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">prctiles</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">90</span><span class="p">],</span>
                                <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_91_0.png" src="../_images/tutorials_prevTrainingExample_91_0.png" />
</div>
</div>
<p>The dashed line stands for the separation between the historical time-steps, and the futuristic time-steps. For each step we compute the relevant percentiles of the attention scores. The attention scores for the further time-steps are zeroed out by design, using the internal masking mechanism within the TFT model. We can see clearly the 7 days cycle among the attention scores, and the general trend according to which the most recent cycles (the ones that are closer to the <em>separation</em> line, are
more dominant than previous, gradually forgotten, cycles.</p>
</div>
<div class="section" id="Multihorizon-Attention">
<h2>Multihorizon Attention<a class="headerlink" href="#Multihorizon-Attention" title="Permalink to this headline">¶</a></h2>
<p>As noted above, each future horizon step has its own set of attention scores. Using the same function we can describe the attention scores distribution for multiple horizons at once.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                <span class="n">horizons</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
                                <span class="n">prctiles</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_94_0.png" src="../_images/tutorials_prevTrainingExample_94_0.png" />
</div>
</div>
<p>We can see that the attention scores for the historical time-steps have quite similiar <em>characteristics</em> among the different horizons. They all are decaying towards the past, they all have weekly cycles, but, their weekly cycles are offset due to the difference in weekdays.</p>
<p>The attention scores can also be explored in the single-sample level using <code class="docutils literal notranslate"><span class="pre">display_sample_wise_attention_scores()</span></code> function. The following chart presents the scores associated with each output horizon (see legend). When we compare scorings of different horizons, we can see that the attention scores signal is somewhat correlated between two differnet horizon.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tft_vis</span><span class="o">.</span><span class="n">display_sample_wise_attention_scores</span><span class="p">(</span><span class="n">attention_scores</span><span class="o">=</span><span class="n">validation_outputs</span><span class="p">[</span><span class="s1">&#39;attention_scores&#39;</span><span class="p">],</span>
                                            <span class="n">observation_index</span><span class="o">=</span><span class="n">chosen_idx</span><span class="p">,</span>
                                            <span class="n">horizons</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span>
                                            <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_prevTrainingExample_97_0.png" src="../_images/tutorials_prevTrainingExample_97_0.png" />
</div>
</div>
<p>And that’s it! Enjoy using <code class="docutils literal notranslate"><span class="pre">tft_torch</span></code></p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Dvir Ben Or.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>